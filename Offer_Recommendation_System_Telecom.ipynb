{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package requirements & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Month of Joining</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Location ID</th>\n",
       "      <th>...</th>\n",
       "      <th>Streaming Movies</th>\n",
       "      <th>Streaming Music</th>\n",
       "      <th>Unlimited Data</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Status ID</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Churn Category</th>\n",
       "      <th>Churn Reason</th>\n",
       "      <th>Customer Status</th>\n",
       "      <th>Churn Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hthjctifkiudi0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71638</td>\n",
       "      <td>Female</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jeavwsrtakgq0</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>vvhwtmkbxtvsppd52013</td>\n",
       "      <td>3</td>\n",
       "      <td>Competitor</td>\n",
       "      <td>Competitor offered higher download speeds</td>\n",
       "      <td>Churned</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>72566</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.472065</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>qcvetdmalnkw1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>jucxaluihiluj82863</td>\n",
       "      <td>4</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>72566</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.442687</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>qcvetdmalnkw1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>vjskkxphumfai57182</td>\n",
       "      <td>3</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>72566</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.837888</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>qcvetdmalnkw1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Wallet Balance</td>\n",
       "      <td>cdwbcrvylqca53109</td>\n",
       "      <td>4</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>72566</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.490214</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>qcvetdmalnkw1</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>whqrmeulitfj98550</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>72566</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.420839</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>qcvetdmalnkw1</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>adzabvpghmbju72072</td>\n",
       "      <td>4</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>72566</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.566777</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>qcvetdmalnkw1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>xjnuhhfmfgtd73026</td>\n",
       "      <td>4</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>72566</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.493271</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>qcvetdmalnkw1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>igrkenxzyvdw27549</td>\n",
       "      <td>3</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>72566</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.480878</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>qcvetdmalnkw1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>srrfeoupvdnwy37904</td>\n",
       "      <td>3</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>72566</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.276942</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>qcvetdmalnkw1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>inebwpymzwpup39698</td>\n",
       "      <td>4</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer ID  Month  Month of Joining  zip_code  Gender        Age  \\\n",
       "0  hthjctifkiudi0      1                 1     71638  Female  36.000000   \n",
       "1  uqdtniwvxqzeu1      6                 6     72566    Male  36.472065   \n",
       "2  uqdtniwvxqzeu1      7                 6     72566    Male  36.442687   \n",
       "3  uqdtniwvxqzeu1      8                 6     72566    Male  36.837888   \n",
       "4  uqdtniwvxqzeu1      9                 6     72566    Male  36.490214   \n",
       "5  uqdtniwvxqzeu1     10                 6     72566    Male  36.420839   \n",
       "6  uqdtniwvxqzeu1     11                 6     72566    Male  36.566777   \n",
       "7  uqdtniwvxqzeu1     12                 6     72566    Male  36.493271   \n",
       "8  uqdtniwvxqzeu1     13                 6     72566    Male  36.480878   \n",
       "9  uqdtniwvxqzeu1     14                 6     72566    Male  36.276942   \n",
       "\n",
       "  Married Dependents  Number of Dependents    Location ID  ...  \\\n",
       "0      No         No                   0.0  jeavwsrtakgq0  ...   \n",
       "1      No         No                   0.0  qcvetdmalnkw1  ...   \n",
       "2      No         No                   0.0  qcvetdmalnkw1  ...   \n",
       "3      No         No                   0.0  qcvetdmalnkw1  ...   \n",
       "4      No         No                   0.0  qcvetdmalnkw1  ...   \n",
       "5      No         No                   0.0  qcvetdmalnkw1  ...   \n",
       "6      No         No                   0.0  qcvetdmalnkw1  ...   \n",
       "7      No         No                   0.0  qcvetdmalnkw1  ...   \n",
       "8      No         No                   0.0  qcvetdmalnkw1  ...   \n",
       "9      No         No                   0.0  qcvetdmalnkw1  ...   \n",
       "\n",
       "  Streaming Movies Streaming Music Unlimited Data   Payment Method  \\\n",
       "0              Yes             Yes            Yes      Credit Card   \n",
       "1               No              No             No  Bank Withdrawal   \n",
       "2               No              No            Yes      Credit Card   \n",
       "3               No              No            Yes   Wallet Balance   \n",
       "4              Yes              No            Yes      Credit Card   \n",
       "5              Yes             Yes            NaN  Bank Withdrawal   \n",
       "6               No              No             No  Bank Withdrawal   \n",
       "7               No              No            Yes  Bank Withdrawal   \n",
       "8               No              No            Yes  Bank Withdrawal   \n",
       "9               No              No             No      Credit Card   \n",
       "\n",
       "              Status ID Satisfaction Score  Churn Category  \\\n",
       "0  vvhwtmkbxtvsppd52013                  3      Competitor   \n",
       "1    jucxaluihiluj82863                  4  Not Applicable   \n",
       "2    vjskkxphumfai57182                  3  Not Applicable   \n",
       "3     cdwbcrvylqca53109                  4  Not Applicable   \n",
       "4     whqrmeulitfj98550                  1  Not Applicable   \n",
       "5    adzabvpghmbju72072                  4  Not Applicable   \n",
       "6     xjnuhhfmfgtd73026                  4  Not Applicable   \n",
       "7     igrkenxzyvdw27549                  3  Not Applicable   \n",
       "8    srrfeoupvdnwy37904                  3  Not Applicable   \n",
       "9    inebwpymzwpup39698                  4  Not Applicable   \n",
       "\n",
       "                                Churn Reason  Customer Status  Churn Value  \n",
       "0  Competitor offered higher download speeds          Churned            1  \n",
       "1                             Not Applicable           Stayed            0  \n",
       "2                             Not Applicable           Stayed            0  \n",
       "3                             Not Applicable           Stayed            0  \n",
       "4                             Not Applicable           Stayed            0  \n",
       "5                             Not Applicable           Stayed            0  \n",
       "6                             Not Applicable           Stayed            0  \n",
       "7                             Not Applicable           Stayed            0  \n",
       "8                             Not Applicable           Stayed            0  \n",
       "9                             Not Applicable           Stayed            0  \n",
       "\n",
       "[10 rows x 74 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path = './data/Telecom_data.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Exploration**\n",
    "\n",
    "Data exploration is a critical step in the data analysis process. Data exploration is important because it helps to provide a solid foundation for subsequent data analysis tasks, hypothesis testing and data visualization.\n",
    "\n",
    "Data exploration is also important because it can help you to identify an appropriate approach for analyzing the data.\n",
    "\n",
    "Here are the various functions that help us explore and understand the data.\n",
    "\n",
    "* Shape: Shape is used to identify the dimensions of the dataset. It gives the number of rows and columns present in the dataset. Knowing the dimensions of the dataset is important to understand the amount of data available for analysis and to determine the feasibility of different methods of analysis.\n",
    "\n",
    "* Head: The head function is used to display the top five rows of the dataset. It helps us to understand the structure and organization of the dataset. This function gives an idea of what data is present in the dataset, what the column headers are, and how the data is organized.\n",
    "\n",
    "* Tail: The tail function is used to display the bottom five rows of the dataset. It provides the same information as the head function but for the bottom rows. The tail function is particularly useful when dealing with large datasets, as it can be time-consuming to scroll through all the rows.\n",
    "\n",
    "* Describe: The describe function provides a summary of the numerical columns in the dataset. It includes the count, mean, standard deviation, minimum, and maximum values, as well as the quartiles. It helps to understand the distribution of the data, the presence of any outliers, and potential issues that can affect the model's accuracy.\n",
    "\n",
    "* Isnull: The isnull function is used to identify missing values in the dataset. It returns a Boolean value for each cell, indicating whether it is null or not. This function is useful to identify the presence of missing data, which can be problematic for regression analysis.\n",
    "\n",
    "* Dropna: The dropna function is used to remove rows or columns with missing data. It is used to remove any observations or variables with missing data, which can lead to biased results in the regression analysis. The dropna function is used after identifying the missing data with the isnull function.\n",
    "\n",
    "* Columns: The .columns method is a built-in function that is used to display the column names of a pandas DataFrame or Series. It returns an array-like object that contains the names of the columns in the order in which they appear in the original DataFrame or Series. It can be used to obtain a quick overview of the variables in a dataset and their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653753, 74)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer ID', 'Month', 'Month of Joining', 'zip_code', 'Gender', 'Age',\n",
       "       'Married', 'Dependents', 'Number of Dependents', 'Location ID',\n",
       "       'Service ID', 'state', 'county', 'timezone', 'area_codes', 'country',\n",
       "       'latitude', 'longitude', 'roam_ic', 'roam_og', 'loc_og_t2t',\n",
       "       'loc_og_t2m', 'loc_og_t2f', 'loc_og_t2c', 'std_og_t2t', 'std_og_t2m',\n",
       "       'std_og_t2f', 'std_og_t2c', 'isd_og', 'spl_og', 'og_others',\n",
       "       'loc_ic_t2t', 'loc_ic_t2m', 'loc_ic_t2f', 'std_ic_t2t', 'std_ic_t2m',\n",
       "       'std_ic_t2f', 'std_ic_t2o', 'spl_ic', 'isd_ic', 'ic_others',\n",
       "       'total_rech_amt', 'total_rech_data', 'vol_4g', 'vol_5g', 'arpu_5g',\n",
       "       'arpu_4g', 'arpu', 'night_pck_user', 'fb_user', 'aug_vbc_5g', 'offer',\n",
       "       'Referred a Friend', 'Number of Referrals', 'Phone Service',\n",
       "       'Multiple Lines', 'Internet Service', 'Internet Type',\n",
       "       'Streaming Data Consumption', 'Online Security', 'Online Backup',\n",
       "       'Device Protection Plan', 'Premium Tech Support', 'Streaming TV',\n",
       "       'Streaming Movies', 'Streaming Music', 'Unlimited Data',\n",
       "       'Payment Method', 'Status ID', 'Satisfaction Score', 'Churn Category',\n",
       "       'Churn Reason', 'Customer Status', 'Churn Value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Dictionary**\n",
    "\n",
    "\n",
    "\n",
    "| Column name\t | Description|\n",
    "| ----- | ----- |\n",
    "| Customer ID\t | Unique identifier for each customer |\n",
    "| Month | Calendar Month- 1:12 | \n",
    "| Month of Joining |\tCalender Month -1:14, Month for which the data is captured|\n",
    "| zip_code |\tZip Code|\n",
    "|Gender |\tGender|\n",
    "| Age |\tAge(Years)|\n",
    "| Married |\tMarital Status |\n",
    "|Dependents | Dependents - Binary |\n",
    "| Number of Dependents |\tNumber of Dependents|\n",
    "|Location ID |\tLocation ID|\n",
    "|Service ID\t |Service ID|\n",
    "|state|\tState|\n",
    "|county\t|County|\n",
    "|timezone\t|Timezone|\n",
    "|area_codes|\tArea Code|\n",
    "|country\t|Country|\n",
    "|latitude|\tLatitude|\n",
    "|longitude\t|Longitude|\n",
    "|arpu|\tAverage revenue per user|\n",
    "|roam_ic\t|Roaming incoming calls in minutes|\n",
    "|roam_og\t|Roaming outgoing calls in minutes|\n",
    "|loc_og_t2t|\tLocal outgoing calls within same network in minutes|\n",
    "|loc_og_t2m\t|Local outgoing calls outside network in minutes(outside same + partner network)|\n",
    "|loc_og_t2f|\tLocal outgoing calls with Partner network in minutes|\n",
    "|loc_og_t2c\t|Local outgoing calls with Call Center in minutes|\n",
    "|std_og_t2t|\tSTD outgoing calls within same network in minutes|\n",
    "|std_og_t2m|\tSTD outgoing calls outside network in minutes(outside same + partner network)|\n",
    "|std_og_t2f|\tSTD outgoing calls with Partner network in minutes|\n",
    "|std_og_t2c\t|STD outgoing calls with Call Center in minutes|\n",
    "|isd_og|\tISD Outgoing calls|\n",
    "|spl_og\t|Special Outgoing calls|\n",
    "|og_others|\tOther Outgoing Calls|\n",
    "|loc_ic_t2t|\tLocal incoming calls within same network in minutes|\n",
    "|loc_ic_t2m|\tLocal incoming calls outside network in minutes(outside same + partner network)|\n",
    "|loc_ic_t2f\t|Local incoming calls with Partner network in minutes|\n",
    "|std_ic_t2t\t|STD incoming calls within same network in minutes|\n",
    "|std_ic_t2m\t|STD incoming calls outside network in minutes(outside same + partner network)|\n",
    "|std_ic_t2f|\tSTD incoming calls with Partner network in minutes|\n",
    "|std_ic_t2o|\tSTD incoming calls operators other networks in minutes|\n",
    "|spl_ic|\tSpecial Incoming calls in minutes|\n",
    "|isd_ic|\tISD Incoming calls in minutes|\n",
    "|ic_others|\tOther Incoming Calls|\n",
    "|total_rech_amt|\tTotal Recharge Amount in Local Currency|\n",
    "|total_rech_data|\tTotal Recharge Amount for Data in Local Currency\n",
    "|vol_4g|\t4G Internet Used in GB|\n",
    "|vol_5g|\t5G Internet used in GB|\n",
    "|arpu_5g|\tAverage revenue per user over 5G network|\n",
    "|arpu_4g|\tAverage revenue per user over 4G network|\n",
    "|night_pck_user|\tIs Night Pack User(Specific Scheme)|\n",
    "|fb_user|\tSocial Networking scheme|\n",
    "|aug_vbc_5g|\tVolume Based cost for 5G network (outside the scheme paid based on extra usage)|\n",
    "|offer|\tOffer Given to User|\n",
    "|Referred a Friend|\tReferred a Friend : Binary|\n",
    "|Number of Referrals|\tNumber of Referrals|\n",
    "|Phone Service|\tPhone Service: Binary|\n",
    "|Multiple Lines|\tMultiple Lines for phone service: Binary|\n",
    "|Internet Service|\tInternet Service: Binary|\n",
    "|Internet Type|\tInternet Type|\n",
    "|Streaming Data Consumption|\tStreaming Data Consumption|\n",
    "|Online Security|\tOnline Security|\n",
    "|Online Backup|\tOnline Backup|\n",
    "|Device Protection Plan|\tDevice Protection Plan|\n",
    "|Premium Tech Support|\tPremium Tech Support|\n",
    "|Streaming TV|\tStreaming TV|\n",
    "|Streaming Movies|\tStreaming Movies|\n",
    "|Streaming Music|\tStreaming Music|\n",
    "|Unlimited Data|\tUnlimited Data|\n",
    "|Payment Method|\tPayment Method|\n",
    "|Status ID|\tStatus ID|\n",
    "|Satisfaction Score|\tSatisfaction Score|\n",
    "|Churn Category|\tChurn Category|\n",
    "|Churn Reason|\tChurn Reason|\n",
    "|Customer Status|\tCustomer Status|\n",
    "|Churn Value|\tBinary Churn Value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 653753 entries, 0 to 653752\n",
      "Data columns (total 74 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Customer ID                 653753 non-null  object \n",
      " 1   Month                       653753 non-null  int64  \n",
      " 2   Month of Joining            653753 non-null  int64  \n",
      " 3   zip_code                    653753 non-null  int64  \n",
      " 4   Gender                      653753 non-null  object \n",
      " 5   Age                         653753 non-null  float64\n",
      " 6   Married                     653753 non-null  object \n",
      " 7   Dependents                  653753 non-null  object \n",
      " 8   Number of Dependents        653753 non-null  float64\n",
      " 9   Location ID                 653753 non-null  object \n",
      " 10  Service ID                  653753 non-null  object \n",
      " 11  state                       653753 non-null  object \n",
      " 12  county                      653753 non-null  object \n",
      " 13  timezone                    653753 non-null  object \n",
      " 14  area_codes                  653753 non-null  object \n",
      " 15  country                     653753 non-null  object \n",
      " 16  latitude                    653753 non-null  float64\n",
      " 17  longitude                   653753 non-null  float64\n",
      " 18  roam_ic                     653753 non-null  float64\n",
      " 19  roam_og                     653753 non-null  float64\n",
      " 20  loc_og_t2t                  653753 non-null  float64\n",
      " 21  loc_og_t2m                  653753 non-null  float64\n",
      " 22  loc_og_t2f                  653753 non-null  float64\n",
      " 23  loc_og_t2c                  653753 non-null  float64\n",
      " 24  std_og_t2t                  653753 non-null  float64\n",
      " 25  std_og_t2m                  653753 non-null  float64\n",
      " 26  std_og_t2f                  653753 non-null  float64\n",
      " 27  std_og_t2c                  653753 non-null  int64  \n",
      " 28  isd_og                      653753 non-null  float64\n",
      " 29  spl_og                      653753 non-null  float64\n",
      " 30  og_others                   653753 non-null  float64\n",
      " 31  loc_ic_t2t                  653753 non-null  float64\n",
      " 32  loc_ic_t2m                  653753 non-null  float64\n",
      " 33  loc_ic_t2f                  653753 non-null  float64\n",
      " 34  std_ic_t2t                  653753 non-null  float64\n",
      " 35  std_ic_t2m                  653753 non-null  float64\n",
      " 36  std_ic_t2f                  653753 non-null  float64\n",
      " 37  std_ic_t2o                  653753 non-null  int64  \n",
      " 38  spl_ic                      653753 non-null  float64\n",
      " 39  isd_ic                      653753 non-null  float64\n",
      " 40  ic_others                   653753 non-null  float64\n",
      " 41  total_rech_amt              653753 non-null  int64  \n",
      " 42  total_rech_data             443849 non-null  float64\n",
      " 43  vol_4g                      653753 non-null  float64\n",
      " 44  vol_5g                      653753 non-null  float64\n",
      " 45  arpu_5g                     653753 non-null  object \n",
      " 46  arpu_4g                     653753 non-null  object \n",
      " 47  arpu                        653753 non-null  float64\n",
      " 48  night_pck_user              280650 non-null  float64\n",
      " 49  fb_user                     243359 non-null  float64\n",
      " 50  aug_vbc_5g                  653753 non-null  float64\n",
      " 51  offer                       653753 non-null  object \n",
      " 52  Referred a Friend           653753 non-null  object \n",
      " 53  Number of Referrals         653753 non-null  float64\n",
      " 54  Phone Service               653753 non-null  object \n",
      " 55  Multiple Lines              607673 non-null  object \n",
      " 56  Internet Service            653753 non-null  object \n",
      " 57  Internet Type               328503 non-null  object \n",
      " 58  Streaming Data Consumption  653753 non-null  int64  \n",
      " 59  Online Security             653753 non-null  object \n",
      " 60  Online Backup               653753 non-null  object \n",
      " 61  Device Protection Plan      653753 non-null  object \n",
      " 62  Premium Tech Support        653753 non-null  object \n",
      " 63  Streaming TV                653753 non-null  object \n",
      " 64  Streaming Movies            653753 non-null  object \n",
      " 65  Streaming Music             653753 non-null  object \n",
      " 66  Unlimited Data              642650 non-null  object \n",
      " 67  Payment Method              653753 non-null  object \n",
      " 68  Status ID                   653753 non-null  object \n",
      " 69  Satisfaction Score          653753 non-null  int64  \n",
      " 70  Churn Category              653753 non-null  object \n",
      " 71  Churn Reason                653753 non-null  object \n",
      " 72  Customer Status             653753 non-null  object \n",
      " 73  Churn Value                 653753 non-null  int64  \n",
      "dtypes: float64(33), int64(9), object(32)\n",
      "memory usage: 369.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Applicable', '0', '106.3', ..., '2573.06', '1092.62',\n",
       "       '1847.93'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"arpu_4g\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Applicable', '0', '106.3', ..., '2573.06', '1092.62',\n",
       "       '1847.93'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"arpu_4g\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'F', 'No Offer', 'J', 'E', 'C', 'I', 'B', 'D', 'H', 'G'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['offer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>% Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>15915</td>\n",
       "      <td>2.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>15871</td>\n",
       "      <td>2.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>16153</td>\n",
       "      <td>2.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>16162</td>\n",
       "      <td>2.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>15833</td>\n",
       "      <td>2.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>15789</td>\n",
       "      <td>2.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>15778</td>\n",
       "      <td>2.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>15855</td>\n",
       "      <td>2.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I</td>\n",
       "      <td>15860</td>\n",
       "      <td>2.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>J</td>\n",
       "      <td>15893</td>\n",
       "      <td>2.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No Offer</td>\n",
       "      <td>494644</td>\n",
       "      <td>75.66%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       offer  Customer ID % Total\n",
       "0          A        15915   2.43%\n",
       "1          B        15871   2.43%\n",
       "2          C        16153   2.47%\n",
       "3          D        16162   2.47%\n",
       "4          E        15833   2.42%\n",
       "5          F        15789   2.42%\n",
       "6          G        15778   2.41%\n",
       "7          H        15855   2.43%\n",
       "8          I        15860   2.43%\n",
       "9          J        15893   2.43%\n",
       "10  No Offer       494644  75.66%"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at the offer distribution\n",
    "dfg = df.groupby('offer').agg({'Customer ID':'count'}).reset_index()\n",
    "dfg['% Total'] = dfg['Customer ID']/dfg['Customer ID'].sum() #this creates a % of total column\n",
    "dfg['% Total'] = dfg['% Total'].apply(lambda x: '{:.2%}'.format(x)) #this function simply formats the column to %\n",
    "dfg #this displays the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "* The Offers seems to be evenly distributed amongst customers\n",
    "* There are about 76% users who did not receive any offer from the company\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "* Is there any way to check impact of offers on churn? \n",
    "* How many customer churned as they were not given any offer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Customer Status</th>\n",
       "      <th>offer</th>\n",
       "      <th>Churned</th>\n",
       "      <th>Stayed</th>\n",
       "      <th>Churn Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1464</td>\n",
       "      <td>14451</td>\n",
       "      <td>9.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1441</td>\n",
       "      <td>14430</td>\n",
       "      <td>9.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>1470</td>\n",
       "      <td>14683</td>\n",
       "      <td>9.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>1484</td>\n",
       "      <td>14678</td>\n",
       "      <td>9.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>1418</td>\n",
       "      <td>14415</td>\n",
       "      <td>8.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>1459</td>\n",
       "      <td>14330</td>\n",
       "      <td>9.24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>1409</td>\n",
       "      <td>14369</td>\n",
       "      <td>8.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>1477</td>\n",
       "      <td>14378</td>\n",
       "      <td>9.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I</td>\n",
       "      <td>1468</td>\n",
       "      <td>14392</td>\n",
       "      <td>9.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>J</td>\n",
       "      <td>1483</td>\n",
       "      <td>14410</td>\n",
       "      <td>9.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No Offer</td>\n",
       "      <td>15292</td>\n",
       "      <td>479352</td>\n",
       "      <td>3.09%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Customer Status     offer  Churned  Stayed Churn Rate\n",
       "0                       A     1464   14451      9.20%\n",
       "1                       B     1441   14430      9.08%\n",
       "2                       C     1470   14683      9.10%\n",
       "3                       D     1484   14678      9.18%\n",
       "4                       E     1418   14415      8.96%\n",
       "5                       F     1459   14330      9.24%\n",
       "6                       G     1409   14369      8.93%\n",
       "7                       H     1477   14378      9.32%\n",
       "8                       I     1468   14392      9.26%\n",
       "9                       J     1483   14410      9.33%\n",
       "10               No Offer    15292  479352      3.09%"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg2 = df.groupby(['offer','Customer Status']).agg({'Customer ID':'count'}).reset_index()\n",
    "pivoted_dfg2 = dfg2.pivot(index='offer', columns='Customer Status', values='Customer ID')\n",
    "pivoted_dfg2 = pivoted_dfg2.reset_index()\n",
    "pivoted_dfg2['Churn Rate'] = pivoted_dfg2['Churned']/(pivoted_dfg2['Churned'] + pivoted_dfg2['Stayed'])\n",
    "pivoted_dfg2['Churn Rate'] = pivoted_dfg2['Churn Rate'].apply(lambda x: '{:.2%}'.format(x)) #this function simply formats the column to %\n",
    "pivoted_dfg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* churn rate seems to be similar amongst customers regardless of the offer they received -> this tells us that maybe offers are not being tailored enough to groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn Category</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>% Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attitude</td>\n",
       "      <td>296</td>\n",
       "      <td>0.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Competitor</td>\n",
       "      <td>5974</td>\n",
       "      <td>0.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dissatisfaction</td>\n",
       "      <td>6001</td>\n",
       "      <td>0.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>622748</td>\n",
       "      <td>95.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other</td>\n",
       "      <td>4356</td>\n",
       "      <td>0.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Price</td>\n",
       "      <td>4381</td>\n",
       "      <td>0.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Support</td>\n",
       "      <td>7538</td>\n",
       "      <td>1.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>1269</td>\n",
       "      <td>0.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bcvjhdjcb</td>\n",
       "      <td>1190</td>\n",
       "      <td>0.18%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Churn Category  Customer ID % Total\n",
       "0         Attitude          296   0.05%\n",
       "1       Competitor         5974   0.91%\n",
       "2  Dissatisfaction         6001   0.92%\n",
       "3   Not Applicable       622748  95.26%\n",
       "4            Other         4356   0.67%\n",
       "5            Price         4381   0.67%\n",
       "6          Support         7538   1.15%\n",
       "7          Unknown         1269   0.19%\n",
       "8        bcvjhdjcb         1190   0.18%"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at the churn category\n",
    "dfg2 = df.groupby(['Churn Category',]).agg({'Customer ID':'count'}).reset_index()\n",
    "dfg2['% Total'] = dfg2['Customer ID']/dfg2['Customer ID'].sum() #this creates a % of total column\n",
    "dfg2['% Total'] = dfg2['% Total'].apply(lambda x: '{:.2%}'.format(x)) #this function simply formats the column to %\n",
    "dfg2 #this displays the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* The Churn Category for Competitor, Dissatisfaction, Price, Support have higher customers\n",
    "* We can give them specific offers which may lead them to stay rather than churning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Questions****\n",
    "\n",
    "* Is there any better way to recommend offers to customers which can impact less churn rate in future?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Missing Value Detection and Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously saw there are some missing values in the data. Lets have a look into that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>fb_user</td>\n",
       "      <td>62.775085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>night_pck_user</td>\n",
       "      <td>57.070943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Internet Type</td>\n",
       "      <td>49.751206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>total_rech_data</td>\n",
       "      <td>32.107539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Multiple Lines</td>\n",
       "      <td>7.048534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>std_og_t2t</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>loc_og_t2c</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>loc_og_t2f</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>loc_og_t2m</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Churn Value</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        column_name  percent_missing\n",
       "49          fb_user        62.775085\n",
       "48   night_pck_user        57.070943\n",
       "57    Internet Type        49.751206\n",
       "42  total_rech_data        32.107539\n",
       "55   Multiple Lines         7.048534\n",
       "..              ...              ...\n",
       "24       std_og_t2t         0.000000\n",
       "23       loc_og_t2c         0.000000\n",
       "22       loc_og_t2f         0.000000\n",
       "21       loc_og_t2m         0.000000\n",
       "73      Churn Value         0.000000\n",
       "\n",
       "[74 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a missing value df with the null values of our original dataframe\n",
    "percent_missing = df.isna().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing.values})\n",
    "\n",
    "#sorting the dataframe by percent missing value \n",
    "missing_value_df.sort_values(by='percent_missing',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "\n",
    "\n",
    "*  Columns 'fb_user' and 'night_pck_user' have more 50% missing value. We will simply drop this from our dataframe\n",
    "* According to data dictionary 'Internet Type' and 'total_rech_data' seems to correlated.\n",
    "*   We need to check for columns 'Internet Type' and 'total_rech_data' and impute missing values if possible\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the variables with more than 50% null values\n",
    "df=df.drop(columns=['fb_user','night_pck_user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209904"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values in total recharge data\n",
    "df['total_rech_data'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325250"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values in Internet Type\n",
    "df['Internet Type'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "*  These missing values may represent customers who have not recharged their account or have recharged but the information has not been recorded.\n",
    "\n",
    "* It is possible that customers with missing recharge data are those who received free data service, and therefore did not need to recharge their account. Alternatively, it is possible that the missing values are due to technical issues, such as data recording errors or system failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Internet Service\n",
       "Yes    209904\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the value counts of Internet Service where total recharge data was null\n",
    "df[df['total_rech_data'].isna()]['Internet Service'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "\n",
    "* It turns out that all customers with missing recharge data have opted for internet service, the next step could be to check if they have used it or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unlimited Data\n",
       "Yes    181040\n",
       "No      28864\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check unlimited data column\n",
    "df[(df['total_rech_data'].isna())]['Unlimited Data'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arpu_4g         arpu_5g       \n",
       "Not Applicable  Not Applicable    195182\n",
       "297.57          8530.983629            4\n",
       "544.17          8536.565906            3\n",
       "395.94          8533.210427            3\n",
       "290.09          8530.814304            3\n",
       "                                   ...  \n",
       "222.42          1468.94                1\n",
       "222.56          8529.28563             1\n",
       "222.67          8529.28812             1\n",
       "222.73          8529.289478            1\n",
       "2559.56         8582.188229            1\n",
       "Name: count, Length: 14247, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check Average Revenue for 4g and 5g when there is no recharge for data\n",
    "df[(df['total_rech_data'].isna())][['arpu_4g','arpu_5g']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "\n",
    "* We can fill the missing values in the total_rech_data column with 0 when the arpu (Average Revenue Per User) is not applicable. This is because the arpu is a measure of the revenue generated per user, and if it is not applicable, it may indicate that the user is not generating any revenue for the company. In such cases, it is reasonable to assume that the total data recharge amount is 0\n",
    "* It is advisable to check with the business before making this decision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all values of total recharge data= 0 where arpu 4g and 5g are not applicable\n",
    "df.loc[(df['arpu_4g']=='Not Applicable') | (df['arpu_5g']=='Not Applicable'),'total_rech_data']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022519208324856637"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing value percentage after imputation\n",
    "df['total_rech_data'].isna().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot fill other values with 0 because they have some ARPU to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.85274721808543"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean of 'total_rech_data' where either 'arpu_4g' or 'arpu_5g' is not equal to 'Not Applicable'\n",
    "arpu_data_mean=df.loc[(df['arpu_4g']!='Not Applicable') | (df['arpu_5g']!='Not Applicable'),'total_rech_data'].mean()\n",
    "arpu_data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in 'total_rech_data' with the mean of 'total_rech_data' where either 'arpu_4g' or 'arpu_5g' is not equal to 'Not Applicable'\n",
    "df['total_rech_data']=df['total_rech_data'].fillna(arpu_data_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_rech_data'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no more missing values in the column ''total_rech_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Internet Type\n",
       "NaN            325250\n",
       "Fiber Optic    134991\n",
       "Cable          112100\n",
       "DSL             81412\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value counts for Internet Type\n",
    "df['Internet Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Internet Service\n",
       "No     236152\n",
       "Yes     89098\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check value counts for Internet Service where Internet Type is null\n",
    "df[df['Internet Type'].isna()]['Internet Service'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All null values in Internet Type does not have Internet Service. Let's fill these null values with Not Applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null values in Internet Type \n",
    "df['Internet Type']=df['Internet Type'].fillna('Not Applicable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 'Not Applicable' with 0 in both 'arpu_4g' and 'arpu_5g and convert them to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Not Applicable' with 0 in 'arpu_4g'\n",
    "df['arpu_4g'] = df['arpu_4g'].replace('Not Applicable', 0)\n",
    "\n",
    "# Replace 'Not Applicable' with 0 in 'arpu_5g'\n",
    "df['arpu_5g'] = df['arpu_5g'].replace('Not Applicable', 0)\n",
    "\n",
    "# Convert 'arpu_4g' to float data type\n",
    "df['arpu_4g'] = df['arpu_4g'].astype(float)\n",
    "\n",
    "# Convert 'arpu_5g' to float data type\n",
    "df['arpu_5g'] = df['arpu_5g'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outlier Detection and Imputation**\n",
    "\n",
    "\n",
    "Outlier detection is a critical data analysis technique that involves identifying and removing data points that are significantly different from the rest of the data. Outliers are data points that lie far away from the rest of the data, and they can significantly influence the statistical analysis and machine learning models' performance. Therefore, identifying and removing outliers is essential to ensure accurate and reliable data analysis results.\n",
    "\n",
    "There are two main approaches for outlier detection: parametric and non-parametric.\n",
    "\n",
    "* Parametric Methods:\n",
    "Parametric methods assume that the data follows a specific distribution, such as a normal distribution. In this approach, outliers are identified by calculating the distance of each data point from the mean of the distribution in terms of the number of standard deviations. Data points that are beyond a certain number of standard deviations (usually three or more) are considered as outliers.\n",
    "\n",
    "One common parametric method is the Z-score method, which calculates the distance of each data point from the mean in terms of standard deviations.\n",
    "Parametric methods can be useful when the data follows a known distribution, but they may not be effective when the data is not normally distributed.\n",
    "\n",
    "* Non-Parametric Methods:\n",
    "Non-parametric methods do not assume any specific distribution of the data. Instead, they rely on the rank or order of the data points. In this approach, outliers are identified by comparing the values of each data point with the values of other data points. Data points that are significantly different from other data points are considered as outliers.\n",
    "\n",
    "Quantiles are an important concept in non-parametric outlier detection methods. They represent values that divide a dataset into equal-sized parts, such as quarters or thirds. The most commonly used quantiles are the median (which divides the data into two equal parts), the first quartile (which divides the data into the lowest 25% and the highest 75%), and the third quartile (which divides the data into the lowest 75% and the highest 25%).\n",
    "\n",
    "The interquartile range (IQR) is another important concept related to quantiles. It is defined as the difference between the third and first quartiles and represents the middle 50% of the data. The IQR can be used to identify outliers by defining a range (known as the Tukey's fence) beyond which any data points are considered outliers.\n",
    "Non-parametric methods can be useful when the data is not normally distributed or when the distribution is unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of continuous columns\n",
    "cts_cols=['Age','Number of Dependents',\n",
    "       'roam_ic', 'roam_og', 'loc_og_t2t',\n",
    "       'loc_og_t2m', 'loc_og_t2f', 'loc_og_t2c', 'std_og_t2t', 'std_og_t2m',\n",
    "       'std_og_t2f', 'std_og_t2c', 'isd_og', 'spl_og', 'og_others',\n",
    "       'loc_ic_t2t', 'loc_ic_t2m', 'loc_ic_t2f', 'std_ic_t2t', 'std_ic_t2m',\n",
    "       'std_ic_t2f', 'std_ic_t2o', 'spl_ic', 'isd_ic', 'ic_others',\n",
    "       'total_rech_amt', 'total_rech_data', 'vol_4g', 'vol_5g', 'arpu_5g',\n",
    "       'arpu_4g', 'arpu', 'aug_vbc_5g', 'Number of Referrals','Satisfaction Score',\n",
    "       'Streaming Data Consumption']   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe with columns as cts_cols and index as quantiles\n",
    "quantile_df=pd.DataFrame(columns=cts_cols,index=[0.1,0.25,0.5,0.75,0.8,0.9,0.95,0.97,0.99])\n",
    "\n",
    "# for each column in cts_cols, calculate the corresponding quantiles and store them in the quantile_df\n",
    "for col in cts_cols:\n",
    "   quantile_df[col]=df[col].quantile([0.1,0.25,0.5,0.75,0.8,0.9,0.95,0.97,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calculating quantiles for each continuous variable in the dataset, we are trying to get an idea about the spread and distribution of the data. Specifically, we are interested in identifying potential outliers in the data.\n",
    "\n",
    "Quantiles divide a distribution into equal proportions. For instance, the 0.25 quantile is the value below which 25% of the observations fall and the 0.75 quantile is the value below which 75% of the observations fall. By calculating quantiles at various levels, we can get a better understanding of the distribution of the data and identify any observations that are too far away from the rest of the data.\n",
    "\n",
    "These quantiles can be used as thresholds to identify potential outliers in the data. Observations with values beyond these thresholds can be considered as potential outliers and further investigation can be carried out to determine if they are true outliers or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>roam_ic</th>\n",
       "      <th>roam_og</th>\n",
       "      <th>loc_og_t2t</th>\n",
       "      <th>loc_og_t2m</th>\n",
       "      <th>loc_og_t2f</th>\n",
       "      <th>loc_og_t2c</th>\n",
       "      <th>std_og_t2t</th>\n",
       "      <th>std_og_t2m</th>\n",
       "      <th>...</th>\n",
       "      <th>total_rech_data</th>\n",
       "      <th>vol_4g</th>\n",
       "      <th>vol_5g</th>\n",
       "      <th>arpu_5g</th>\n",
       "      <th>arpu_4g</th>\n",
       "      <th>arpu</th>\n",
       "      <th>aug_vbc_5g</th>\n",
       "      <th>Number of Referrals</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Streaming Data Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-256.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.090000</td>\n",
       "      <td>14.710</td>\n",
       "      <td>32.7000</td>\n",
       "      <td>26.260000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>33.120000</td>\n",
       "      <td>25.560000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.9400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.560000</td>\n",
       "      <td>75.100</td>\n",
       "      <td>171.3300</td>\n",
       "      <td>135.460000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>8.180000</td>\n",
       "      <td>174.600000</td>\n",
       "      <td>134.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.0100</td>\n",
       "      <td>362.3800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>348.5400</td>\n",
       "      <td>117.3200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>162.030000</td>\n",
       "      <td>135.280</td>\n",
       "      <td>309.0900</td>\n",
       "      <td>618.210000</td>\n",
       "      <td>14.090000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>316.240000</td>\n",
       "      <td>244.490000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>154.9000</td>\n",
       "      <td>964.7200</td>\n",
       "      <td>194.470000</td>\n",
       "      <td>228.220000</td>\n",
       "      <td>580.6500</td>\n",
       "      <td>311.7500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>496.902000</td>\n",
       "      <td>146.820</td>\n",
       "      <td>856.7660</td>\n",
       "      <td>1392.937844</td>\n",
       "      <td>43.870000</td>\n",
       "      <td>15.970000</td>\n",
       "      <td>344.970000</td>\n",
       "      <td>266.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.852747</td>\n",
       "      <td>176.3600</td>\n",
       "      <td>3814.2220</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>783.290000</td>\n",
       "      <td>626.2300</td>\n",
       "      <td>350.4900</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>55.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>969.043806</td>\n",
       "      <td>689.598</td>\n",
       "      <td>3613.9960</td>\n",
       "      <td>2644.568000</td>\n",
       "      <td>126.593474</td>\n",
       "      <td>109.097149</td>\n",
       "      <td>1547.136000</td>\n",
       "      <td>1007.842370</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>219.2680</td>\n",
       "      <td>12369.5160</td>\n",
       "      <td>2219.752000</td>\n",
       "      <td>2224.100000</td>\n",
       "      <td>1901.5140</td>\n",
       "      <td>789.0000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1283.198000</td>\n",
       "      <td>1954.392</td>\n",
       "      <td>5079.8300</td>\n",
       "      <td>3479.438000</td>\n",
       "      <td>183.490000</td>\n",
       "      <td>207.514000</td>\n",
       "      <td>3953.108671</td>\n",
       "      <td>3108.617986</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>663.2040</td>\n",
       "      <td>17358.4180</td>\n",
       "      <td>8530.865147</td>\n",
       "      <td>8675.302558</td>\n",
       "      <td>5892.6180</td>\n",
       "      <td>3943.2100</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.97</th>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1494.043200</td>\n",
       "      <td>2550.390</td>\n",
       "      <td>5806.0544</td>\n",
       "      <td>3756.444400</td>\n",
       "      <td>206.750000</td>\n",
       "      <td>277.344400</td>\n",
       "      <td>5344.123200</td>\n",
       "      <td>3848.301590</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1438.5100</td>\n",
       "      <td>19569.9704</td>\n",
       "      <td>8724.440600</td>\n",
       "      <td>8839.721689</td>\n",
       "      <td>7592.5688</td>\n",
       "      <td>5949.3792</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.99</th>\n",
       "      <td>74.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1646.899600</td>\n",
       "      <td>3041.760</td>\n",
       "      <td>6191.2040</td>\n",
       "      <td>4060.298800</td>\n",
       "      <td>257.650000</td>\n",
       "      <td>311.464800</td>\n",
       "      <td>6729.403200</td>\n",
       "      <td>4875.216400</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4289.8496</td>\n",
       "      <td>254687.0000</td>\n",
       "      <td>254687.000000</td>\n",
       "      <td>254687.000000</td>\n",
       "      <td>8846.9584</td>\n",
       "      <td>7366.7684</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Number of Dependents      roam_ic   roam_og  loc_og_t2t  \\\n",
       "0.10  24.0                   0.0     0.000000     0.000      0.0000   \n",
       "0.25  28.0                   0.0    12.090000    14.710     32.7000   \n",
       "0.50  34.0                   0.0    50.560000    75.100    171.3300   \n",
       "0.75  43.0                   1.0   162.030000   135.280    309.0900   \n",
       "0.80  47.0                   2.0   496.902000   146.820    856.7660   \n",
       "0.90  55.0                   4.0   969.043806   689.598   3613.9960   \n",
       "0.95  61.0                   7.0  1283.198000  1954.392   5079.8300   \n",
       "0.97  64.0                   8.0  1494.043200  2550.390   5806.0544   \n",
       "0.99  74.0                   9.0  1646.899600  3041.760   6191.2040   \n",
       "\n",
       "       loc_og_t2m  loc_og_t2f  loc_og_t2c   std_og_t2t   std_og_t2m  ...  \\\n",
       "0.10     0.000000    0.000000    0.000000     0.000000     0.000000  ...   \n",
       "0.25    26.260000    1.460000    1.610000    33.120000    25.560000  ...   \n",
       "0.50   135.460000    7.800000    8.180000   174.600000   134.800000  ...   \n",
       "0.75   618.210000   14.090000   14.700000   316.240000   244.490000  ...   \n",
       "0.80  1392.937844   43.870000   15.970000   344.970000   266.540000  ...   \n",
       "0.90  2644.568000  126.593474  109.097149  1547.136000  1007.842370  ...   \n",
       "0.95  3479.438000  183.490000  207.514000  3953.108671  3108.617986  ...   \n",
       "0.97  3756.444400  206.750000  277.344400  5344.123200  3848.301590  ...   \n",
       "0.99  4060.298800  257.650000  311.464800  6729.403200  4875.216400  ...   \n",
       "\n",
       "      total_rech_data     vol_4g       vol_5g        arpu_5g        arpu_4g  \\\n",
       "0.10         0.000000     0.0000       0.0000       0.000000       0.000000   \n",
       "0.25         0.000000     0.0000       0.0000       0.000000       0.000000   \n",
       "0.50         0.000000    47.0100     362.3800       0.000000       0.000000   \n",
       "0.75         2.000000   154.9000     964.7200     194.470000     228.220000   \n",
       "0.80         4.852747   176.3600    3814.2220     789.000000     783.290000   \n",
       "0.90        14.000000   219.2680   12369.5160    2219.752000    2224.100000   \n",
       "0.95        23.000000   663.2040   17358.4180    8530.865147    8675.302558   \n",
       "0.97        26.000000  1438.5100   19569.9704    8724.440600    8839.721689   \n",
       "0.99        30.000000  4289.8496  254687.0000  254687.000000  254687.000000   \n",
       "\n",
       "           arpu  aug_vbc_5g  Number of Referrals  Satisfaction Score  \\\n",
       "0.10  -256.2000      0.0000                  0.0                 1.0   \n",
       "0.25   118.9400      0.0000                  0.0                 3.0   \n",
       "0.50   348.5400    117.3200                  4.0                 3.0   \n",
       "0.75   580.6500    311.7500                  8.0                 4.0   \n",
       "0.80   626.2300    350.4900                  8.0                 4.0   \n",
       "0.90  1901.5140    789.0000                 10.0                 5.0   \n",
       "0.95  5892.6180   3943.2100                 11.0                 5.0   \n",
       "0.97  7592.5688   5949.3792                 11.0                 5.0   \n",
       "0.99  8846.9584   7366.7684                 11.0                 5.0   \n",
       "\n",
       "      Streaming Data Consumption  \n",
       "0.10                         0.0  \n",
       "0.25                         2.0  \n",
       "0.50                        20.0  \n",
       "0.75                        49.0  \n",
       "0.80                        56.0  \n",
       "0.90                        69.0  \n",
       "0.95                        77.0  \n",
       "0.97                        80.0  \n",
       "0.99                        83.0  \n",
       "\n",
       "[9 rows x 36 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the quantiles df\n",
    "quantile_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The variables vol_5g, arpu_4g, and arpu_5g seems to have some abrupt values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750       228.220000\n",
       "0.800       783.290000\n",
       "0.900      2224.100000\n",
       "0.950      8675.302558\n",
       "0.970      8839.721689\n",
       "0.990    254687.000000\n",
       "0.999    254687.000000\n",
       "Name: arpu_4g, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking further\n",
    "df['arpu_4g'].quantile([0.75,0.8,0.9,0.95,0.97,0.99,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019651152652454366"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the proportion of rows in the DataFrame where the value in the 'arpu_4g' column is equal to 254687\n",
    "df[df['arpu_4g']==254687].shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what is the value of 'total_rech_data' for these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rech_data\n",
       "0.0    12847\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the value counts of 'total_rech_data' for observations where the value in the 'arpu_4g' column is equal to 254687\n",
    "df[df['arpu_4g']==254687]['total_rech_data'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since the recharge amount is 0 and there is no ARPU, let's replace it with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the outlier value 254687 in the 'arpu_4g' column of the dataframe 'df' with 0.\n",
    "df['arpu_4g']=df['arpu_4g'].replace(254687,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750      120.570000\n",
       "0.800      504.112000\n",
       "0.900     1893.758000\n",
       "0.950     2493.880000\n",
       "0.970     8675.470757\n",
       "0.990     8839.721689\n",
       "0.999    87978.000000\n",
       "Name: arpu_4g, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking further\n",
    "df['arpu_4g'].quantile([0.75,0.8,0.9,0.95,0.97,0.99,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rech_data\n",
       "0.0    5007\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter by 'arpu_4g' value of 87978 and count unique values in 'total_rech_data' column\n",
    "df[df['arpu_4g']==87978]['total_rech_data'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All rows in the dataframe with an 'arpu_4g' value of 87978 have 0 value in the 'total_rech_data' column, indicating that these are likely outliers. Therefore, we have decided to replace the 'arpu_4g' value for these rows with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the values with 0\n",
    "df['arpu_4g']=df['arpu_4g'].replace(87978,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750     107.760000\n",
       "0.800     432.246000\n",
       "0.900    1803.560000\n",
       "0.950    2424.072000\n",
       "0.970    2735.554400\n",
       "0.990    8705.097343\n",
       "0.999    8839.721689\n",
       "Name: arpu_4g, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the quantiles again\n",
    "df['arpu_4g'].quantile([0.75,0.8,0.9,0.95,0.97,0.99,0.999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be fairly good now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rech_data\n",
       "0.0    12614\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the value counts of 'total_rech_data' for observations where the value in the 'arpu_5g' column is equal to 254687\n",
    "df[df['arpu_5g']==254687]['total_rech_data'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rech_data\n",
       "0.0    5130\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the value counts of 'total_rech_data' for observations where the value in the 'arpu_5g' column is equal to 87978\n",
    "df[df['arpu_5g']==87978]['total_rech_data'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the values with 0 where total recharge data is 0\n",
    "df['arpu_5g']=df['arpu_5g'].replace([87978,254687],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750      96.490000\n",
       "0.800     417.102000\n",
       "0.900    1797.618000\n",
       "0.950    2543.904000\n",
       "0.970    2792.060000\n",
       "0.990    8587.153966\n",
       "0.999    8724.440600\n",
       "Name: arpu_5g, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the quantiles of ARPU 5G\n",
    "df['arpu_5g'].quantile([0.75,0.8,0.9,0.95,0.97,0.99,0.999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be fairly good now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750       964.7200\n",
       "0.800      3814.2220\n",
       "0.900     12369.5160\n",
       "0.950     17358.4180\n",
       "0.970     19569.9704\n",
       "0.980     87978.0000\n",
       "0.990    254687.0000\n",
       "0.999    254687.0000\n",
       "Name: vol_5g, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the quantiles of Volume of 5G data\n",
    "df['vol_5g'].quantile([0.75,0.8,0.9,0.95,0.97,0.98,0.99,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rech_data\n",
       "0.0    18072\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see the recharge data value for vol_5g more than 87978\n",
    "df[df['vol_5g']>=87978]['total_rech_data'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rech_data\n",
       "0.0    0.027643\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of these values\n",
    "df[df['vol_5g']>=87978]['total_rech_data'].value_counts()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "\n",
    "There is a presence of 2% outliers in vol 5g, where the values are very high, but their total recharge data is 0. We will fill these outliers with 0, and below are some possible reasons why this could be:\n",
    "\n",
    "* Data recording error: It is possible that there was an error in recording the recharge data for these outliers, leading to an incorrect value of 0. In this case, it would make sense to fill the outliers with 0, as this is likely the correct value.\n",
    "\n",
    "* Promotions or bonuses: Another possibility is that these customers received promotions or bonuses that allowed them to use the service without recharging, leading to a total recharge data of 0. However, these customers may still be using the service heavily, leading to the high values in vol 5g. In this case, filling the outliers with 0 would make sense as it accurately reflects the lack of recharge data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the outlier values\n",
    "df['vol_5g']=df['vol_5g'].replace([87978,254687],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750      895.8100\n",
       "0.800     1654.5460\n",
       "0.900     9658.3760\n",
       "0.950    14517.6400\n",
       "0.970    16580.3764\n",
       "0.980    17551.8796\n",
       "0.990    18614.5528\n",
       "0.999    19746.1824\n",
       "Name: vol_5g, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the quantiles of Volume of 5G data\n",
    "df['vol_5g'].quantile([0.75,0.8,0.9,0.95,0.97,0.98,0.99,0.999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems good now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets store this processed data for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/output/processed_telecom_offer_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preprocessing and Leakage**\n",
    "\n",
    "Data leakage is a situation where information from the test or prediction data is inadvertently used during the training process of a machine learning model. This can occur when information from the test or prediction data is leaked into the training data, and the model uses this information to improve its performance during the training process.\n",
    "\n",
    "Data leakage can occur during the preprocessing phase of machine learning when information from the test or prediction data is used to preprocess the training data, inadvertently leaking information from the test or prediction data into the training data.\n",
    "\n",
    "For example, consider a scenario where the preprocessing step involves imputing missing values in the dataset. If the missing values are imputed using the mean or median values of the entire dataset, including the test and prediction data, then the imputed values in the training data may be influenced by the values in the test and prediction data. This can lead to data leakage, as the model may learn to recognize patterns in the test and prediction data during the training process, leading to overfitting and poor generalization performance.\n",
    "\n",
    "\n",
    "To avoid data leakage, it's important to perform the data preprocessing steps on the training data only, and then apply the same preprocessing steps to the test and prediction data separately. This ensures that the test and prediction data remain unseen by the model during the training process, and helps to prevent overfitting and improve the accuracy of the model.\n",
    "\n",
    "In the context of this problem, we performed all data preprocessing steps together for the sake of simplicity, which could potentially lead to data leakage. However, in real-world scenarios, it's important to treat the test and prediction data separately and apply the necessary preprocessing steps separately, based on the characteristics of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by doing some variable selection and transformation. For selection, at this stage, we are going to use some business judgement to stick to what is possible to work with all the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Splitting the dataset into a training and production dataset:**\n",
    "\n",
    "- Training: part of the customers who received offers which will be used to train the model\n",
    "- Production: customers who did not received offers to whom we'd like to then offer something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split our dataframe in a training and production dataset:\n",
    "def split_dataframe(data):\n",
    "    train = data[data['offer']!='No Offer']\n",
    "    production = data[data['offer']=='No Offer']\n",
    "    return train, production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, production = split_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159109, 72), (494644, 72))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,production.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "\n",
    "Why we split the dataframe into such unusual technique?\n",
    "\n",
    "Here we are not dealing with traditional train test split method as we are building an unsupervised collaborative recommender system.\n",
    "Now to make model learn we need to pass all the data with respect to offers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are creating 2 dataframes for each train and production, that have the Customer ID as a join key. This will help us manipulate features, and also trace them back to a particular customer;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This help us identify the customer and the business outcomes\n",
    "id_variables = ['Customer ID', 'Month','Month of Joining','offer','Churn Category',\n",
    "       'Churn Reason', 'Customer Status', 'Churn Value']\n",
    "\n",
    "\n",
    "#This helps us identify the different profiles of customers\n",
    "selected_variables = ['Customer ID', 'Month', 'Month of Joining', 'Gender', 'Age',\n",
    "                      'Married', 'Number of Dependents', 'area_codes','roam_ic', 'roam_og',\n",
    "                      'loc_og_t2t','loc_og_t2m', 'loc_og_t2f', 'loc_og_t2c', 'std_og_t2t', 'std_og_t2m',\n",
    "                      'std_og_t2f', 'std_og_t2c', 'isd_og', 'spl_og', 'og_others',\n",
    "                      'loc_ic_t2t', 'loc_ic_t2m', 'loc_ic_t2f', 'std_ic_t2t', 'std_ic_t2m',\n",
    "                      'std_ic_t2f', 'std_ic_t2o', 'spl_ic', 'isd_ic', 'ic_others',\n",
    "                      'total_rech_amt', 'total_rech_data', 'vol_4g', 'vol_5g', 'arpu_5g',\n",
    "                      'arpu_4g', 'arpu', 'aug_vbc_5g','Number of Referrals', 'Phone Service',\n",
    "                      'Multiple Lines', 'Internet Service', 'Internet Type',\n",
    "                      'Streaming Data Consumption', 'Online Security', 'Online Backup',\n",
    "                      'Device Protection Plan', 'Premium Tech Support', 'Streaming TV',\n",
    "                      'Streaming Movies', 'Streaming Music', 'Unlimited Data',\n",
    "                      'Payment Method']\n",
    "\n",
    "train_id=train[id_variables]\n",
    "train_feat=train[selected_variables]\n",
    "\n",
    "prod_id=production[id_variables]\n",
    "prod_feat=production[selected_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, what we have essentially eliminated are complex variables like latitude, longitude and timezone because they could be represented by the area_codes variable, that represents location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**2. Converting the Month of Joining into a customer tenure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\2509795028.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_feat['tenure'] = train_feat['Month']- train_feat['Month of Joining']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    159109.000000\n",
       "mean          3.232708\n",
       "std           2.815985\n",
       "min           0.000000\n",
       "25%           1.000000\n",
       "50%           3.000000\n",
       "75%           5.000000\n",
       "max          13.000000\n",
       "Name: tenure, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat['tenure'] = train_feat['Month']- train_feat['Month of Joining']\n",
    "train_feat['tenure'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1098919431.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_feat['tenure'] = prod_feat['Month']- prod_feat['Month of Joining']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    494644.000000\n",
       "mean          3.830003\n",
       "std           3.018754\n",
       "min           0.000000\n",
       "25%           1.000000\n",
       "50%           3.000000\n",
       "75%           6.000000\n",
       "max          13.000000\n",
       "Name: tenure, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_feat['tenure'] = prod_feat['Month']- prod_feat['Month of Joining']\n",
    "prod_feat['tenure'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.Transforming Categorical Variables**\n",
    "\n",
    "Transforming variables is an important step in the data preprocessing pipeline of machine learning, as it helps to convert the data into a format that is suitable for analysis and modeling. There are several ways to transform variables, depending on the type and nature of the data.\n",
    "\n",
    "Categorical variables, for example, are variables that take on discrete values from a finite set of categories, such as colors, gender, or occupation. One common way to transform categorical variables is through one-hot encoding. One-hot encoding involves creating a new binary variable for each category in the original variable, where the value is 1 if the observation belongs to that category and 0 otherwise. This approach is useful when the categories have no natural order or ranking.\n",
    "\n",
    "Another way to transform categorical variables is through label encoding. Label encoding involves assigning a unique integer value to each category in the variable. This approach is useful when the categories have a natural order or ranking, such as low, medium, and high.\n",
    "Transforming categorical features into numerical labels:\n",
    "\n",
    "**Note:** We are NOT using dummies here to minimize the explosion of columns because of the distance methods we are using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to transform the features of the feature store.\n",
    "def encode_categorical_features(train_df,prod_df):\n",
    "    # Get a list of all categorical columns\n",
    "    cat_columns = train_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # Encode each categorical column\n",
    "    for col in cat_columns:\n",
    "        le = LabelEncoder()\n",
    "        train_df[col] = le.fit_transform(train_df[col])\n",
    "        prod_df[col]= le.transform(prod_df[col])\n",
    "    return train_df, prod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = le.fit_transform(train_df[col])\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\1391466617.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_df[col]= le.transform(prod_df[col])\n"
     ]
    }
   ],
   "source": [
    "#excluding the customer ID so it doesn't get encoded\n",
    "train_label_data=train_feat[train_feat.columns.difference(['Customer ID','Month','Month of Joining'])]\n",
    "prod_label_data=prod_feat[prod_feat.columns.difference(['Customer ID','Month','Month of Joining'])]\n",
    "train_feat_enc, prod_feat_enc = encode_categorical_features(train_label_data,prod_label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\289144358.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_feat_enc['Customer ID'] = train_feat['Customer ID'] #bringing back the customer id\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\289144358.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_feat_enc['Month'] = train_feat['Month'] #bringing back the Month\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\289144358.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_feat_enc['Customer ID'] = prod_feat['Customer ID'] #bringing back the customer id\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Temp\\ipykernel_9736\\289144358.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prod_feat_enc['Month'] = prod_feat['Month'] #bringing back the Month\n"
     ]
    }
   ],
   "source": [
    "##bringing back the customer ids keys\n",
    "train_feat_enc['Customer ID'] = train_feat['Customer ID'] #bringing back the customer id\n",
    "train_feat_enc['Month'] = train_feat['Month'] #bringing back the Month\n",
    "train_feat_enc['Month of Joining'] = train_feat['Month of Joining'] #bringing back the Month of joining\n",
    "\n",
    "prod_feat_enc['Customer ID'] = prod_feat['Customer ID'] #bringing back the customer id\n",
    "prod_feat_enc['Month'] = prod_feat['Month'] #bringing back the Month\n",
    "prod_feat_enc['Month of Joining'] = prod_feat['Month of Joining'] #bringing back the Month of joining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the final list of variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>36.634975</td>\n",
       "      <td>12.179496</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>28.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Device Protection Plan</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.498514</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.782690</td>\n",
       "      <td>0.842949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internet Service</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.609670</td>\n",
       "      <td>0.487826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internet Type</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>2.031400</td>\n",
       "      <td>1.142408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>1.005041</td>\n",
       "      <td>0.921703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiple Lines</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.577089</td>\n",
       "      <td>0.621380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Dependents</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>1.162522</td>\n",
       "      <td>2.248864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Referrals</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>4.338764</td>\n",
       "      <td>3.768069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Online Backup</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.331169</td>\n",
       "      <td>0.470635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Online Security</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.136655</td>\n",
       "      <td>0.343484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment Method</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.501637</td>\n",
       "      <td>0.629735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phone Service</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.393575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Premium Tech Support</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.256604</td>\n",
       "      <td>0.436760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Streaming Data Consumption</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>27.620311</td>\n",
       "      <td>26.405922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Streaming Movies</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.487433</td>\n",
       "      <td>0.499844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Streaming Music</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.452495</td>\n",
       "      <td>0.497740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Streaming TV</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.492744</td>\n",
       "      <td>0.499949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unlimited Data</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.573739</td>\n",
       "      <td>0.528198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_codes</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>104.663363</td>\n",
       "      <td>47.738883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.00</td>\n",
       "      <td>101.00</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>787.781422</td>\n",
       "      <td>1821.880455</td>\n",
       "      <td>-2258.680000</td>\n",
       "      <td>118.31</td>\n",
       "      <td>348.41</td>\n",
       "      <td>582.400000</td>\n",
       "      <td>9393.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_4g</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>527.772801</td>\n",
       "      <td>1509.454852</td>\n",
       "      <td>-10.470000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>112.630000</td>\n",
       "      <td>8839.721689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_5g</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>519.516787</td>\n",
       "      <td>1450.299521</td>\n",
       "      <td>-16.660000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.440000</td>\n",
       "      <td>8724.440600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aug_vbc_5g</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>534.952343</td>\n",
       "      <td>1411.039501</td>\n",
       "      <td>-374.893876</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117.53</td>\n",
       "      <td>311.790000</td>\n",
       "      <td>8213.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ic_others</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>145.249469</td>\n",
       "      <td>294.250186</td>\n",
       "      <td>-58.302931</td>\n",
       "      <td>20.28</td>\n",
       "      <td>40.65</td>\n",
       "      <td>60.950000</td>\n",
       "      <td>1344.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_ic</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>261.283237</td>\n",
       "      <td>451.011518</td>\n",
       "      <td>-14.001715</td>\n",
       "      <td>27.45</td>\n",
       "      <td>54.45</td>\n",
       "      <td>96.630000</td>\n",
       "      <td>1873.110208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>50.285346</td>\n",
       "      <td>114.062569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.20</td>\n",
       "      <td>17.31</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>764.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2f</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>337.518664</td>\n",
       "      <td>487.475776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.39</td>\n",
       "      <td>72.81</td>\n",
       "      <td>513.910000</td>\n",
       "      <td>1872.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2m</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>734.177204</td>\n",
       "      <td>1015.897612</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>85.68</td>\n",
       "      <td>170.63</td>\n",
       "      <td>1123.240000</td>\n",
       "      <td>3783.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2t</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>862.141763</td>\n",
       "      <td>1225.340083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.10</td>\n",
       "      <td>173.79</td>\n",
       "      <td>1289.270000</td>\n",
       "      <td>4363.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2c</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>30.622222</td>\n",
       "      <td>67.914134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.59</td>\n",
       "      <td>8.21</td>\n",
       "      <td>14.740000</td>\n",
       "      <td>336.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2f</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>33.866195</td>\n",
       "      <td>60.749211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.47</td>\n",
       "      <td>7.92</td>\n",
       "      <td>18.110000</td>\n",
       "      <td>283.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2m</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>690.491017</td>\n",
       "      <td>1121.662647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.42</td>\n",
       "      <td>136.78</td>\n",
       "      <td>706.180000</td>\n",
       "      <td>4212.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2t</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>863.250198</td>\n",
       "      <td>1615.391031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.18</td>\n",
       "      <td>174.06</td>\n",
       "      <td>313.460000</td>\n",
       "      <td>6431.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>100.045559</td>\n",
       "      <td>162.479243</td>\n",
       "      <td>-12.746303</td>\n",
       "      <td>3.42</td>\n",
       "      <td>17.99</td>\n",
       "      <td>116.830000</td>\n",
       "      <td>609.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>254.970469</td>\n",
       "      <td>429.280935</td>\n",
       "      <td>-14.457620</td>\n",
       "      <td>12.18</td>\n",
       "      <td>51.21</td>\n",
       "      <td>196.853003</td>\n",
       "      <td>1719.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_og</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>270.779801</td>\n",
       "      <td>630.702608</td>\n",
       "      <td>-46.888839</td>\n",
       "      <td>14.40</td>\n",
       "      <td>75.02</td>\n",
       "      <td>135.550000</td>\n",
       "      <td>3161.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_ic</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.253568</td>\n",
       "      <td>0.440783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_og</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>92.872855</td>\n",
       "      <td>172.090449</td>\n",
       "      <td>-6.040013</td>\n",
       "      <td>4.96</td>\n",
       "      <td>26.16</td>\n",
       "      <td>46.960000</td>\n",
       "      <td>1018.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2f</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>127.794441</td>\n",
       "      <td>186.599548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.61</td>\n",
       "      <td>25.31</td>\n",
       "      <td>193.570000</td>\n",
       "      <td>663.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2m</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>311.311197</td>\n",
       "      <td>440.434224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.51</td>\n",
       "      <td>65.54</td>\n",
       "      <td>460.946724</td>\n",
       "      <td>1619.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2o</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2t</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>382.092398</td>\n",
       "      <td>640.856736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.88</td>\n",
       "      <td>85.67</td>\n",
       "      <td>217.137387</td>\n",
       "      <td>2527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2c</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2f</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>35.577383</td>\n",
       "      <td>58.438310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.19</td>\n",
       "      <td>6.38</td>\n",
       "      <td>42.200000</td>\n",
       "      <td>217.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2m</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>449.000563</td>\n",
       "      <td>1001.875646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.17</td>\n",
       "      <td>134.70</td>\n",
       "      <td>245.690000</td>\n",
       "      <td>5622.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2t</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>588.507109</td>\n",
       "      <td>1323.372777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.70</td>\n",
       "      <td>175.88</td>\n",
       "      <td>318.040000</td>\n",
       "      <td>7366.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>3.232708</td>\n",
       "      <td>2.815985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_amt</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>1705.510147</td>\n",
       "      <td>2998.602415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.00</td>\n",
       "      <td>375.00</td>\n",
       "      <td>1108.000000</td>\n",
       "      <td>11899.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_data</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>3.435053</td>\n",
       "      <td>7.229865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_4g</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>191.741808</td>\n",
       "      <td>590.745873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.35</td>\n",
       "      <td>154.600000</td>\n",
       "      <td>4503.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_5g</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>2267.762985</td>\n",
       "      <td>4595.365953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>289.16</td>\n",
       "      <td>900.670000</td>\n",
       "      <td>19872.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>9.408556</td>\n",
       "      <td>3.450255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month of Joining</th>\n",
       "      <td>159109.0</td>\n",
       "      <td>6.175848</td>\n",
       "      <td>2.879792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count         mean          std          min  \\\n",
       "Age                         159109.0    36.634975    12.179496    19.000000   \n",
       "Device Protection Plan      159109.0     0.498514     0.499999     0.000000   \n",
       "Gender                      159109.0     0.782690     0.842949     0.000000   \n",
       "Internet Service            159109.0     0.609670     0.487826     0.000000   \n",
       "Internet Type               159109.0     2.031400     1.142408     0.000000   \n",
       "Married                     159109.0     1.005041     0.921703     0.000000   \n",
       "Multiple Lines              159109.0     0.577089     0.621380     0.000000   \n",
       "Number of Dependents        159109.0     1.162522     2.248864     0.000000   \n",
       "Number of Referrals         159109.0     4.338764     3.768069     0.000000   \n",
       "Online Backup               159109.0     0.331169     0.470635     0.000000   \n",
       "Online Security             159109.0     0.136655     0.343484     0.000000   \n",
       "Payment Method              159109.0     0.501637     0.629735     0.000000   \n",
       "Phone Service               159109.0     0.808383     0.393575     0.000000   \n",
       "Premium Tech Support        159109.0     0.256604     0.436760     0.000000   \n",
       "Streaming Data Consumption  159109.0    27.620311    26.405922     0.000000   \n",
       "Streaming Movies            159109.0     0.487433     0.499844     0.000000   \n",
       "Streaming Music             159109.0     0.452495     0.497740     0.000000   \n",
       "Streaming TV                159109.0     0.492744     0.499949     0.000000   \n",
       "Unlimited Data              159109.0     0.573739     0.528198     0.000000   \n",
       "area_codes                  159109.0   104.663363    47.738883     0.000000   \n",
       "arpu                        159109.0   787.781422  1821.880455 -2258.680000   \n",
       "arpu_4g                     159109.0   527.772801  1509.454852   -10.470000   \n",
       "arpu_5g                     159109.0   519.516787  1450.299521   -16.660000   \n",
       "aug_vbc_5g                  159109.0   534.952343  1411.039501  -374.893876   \n",
       "ic_others                   159109.0   145.249469   294.250186   -58.302931   \n",
       "isd_ic                      159109.0   261.283237   451.011518   -14.001715   \n",
       "isd_og                      159109.0    50.285346   114.062569     0.000000   \n",
       "loc_ic_t2f                  159109.0   337.518664   487.475776     0.000000   \n",
       "loc_ic_t2m                  159109.0   734.177204  1015.897612     0.010000   \n",
       "loc_ic_t2t                  159109.0   862.141763  1225.340083     0.000000   \n",
       "loc_og_t2c                  159109.0    30.622222    67.914134     0.000000   \n",
       "loc_og_t2f                  159109.0    33.866195    60.749211     0.000000   \n",
       "loc_og_t2m                  159109.0   690.491017  1121.662647     0.000000   \n",
       "loc_og_t2t                  159109.0   863.250198  1615.391031     0.000000   \n",
       "og_others                   159109.0   100.045559   162.479243   -12.746303   \n",
       "roam_ic                     159109.0   254.970469   429.280935   -14.457620   \n",
       "roam_og                     159109.0   270.779801   630.702608   -46.888839   \n",
       "spl_ic                      159109.0     0.253568     0.440783     0.000000   \n",
       "spl_og                      159109.0    92.872855   172.090449    -6.040013   \n",
       "std_ic_t2f                  159109.0   127.794441   186.599548     0.000000   \n",
       "std_ic_t2m                  159109.0   311.311197   440.434224     0.000000   \n",
       "std_ic_t2o                  159109.0     0.000000     0.000000     0.000000   \n",
       "std_ic_t2t                  159109.0   382.092398   640.856736     0.000000   \n",
       "std_og_t2c                  159109.0     0.000000     0.000000     0.000000   \n",
       "std_og_t2f                  159109.0    35.577383    58.438310     0.000000   \n",
       "std_og_t2m                  159109.0   449.000563  1001.875646     0.000000   \n",
       "std_og_t2t                  159109.0   588.507109  1323.372777     0.000000   \n",
       "tenure                      159109.0     3.232708     2.815985     0.000000   \n",
       "total_rech_amt              159109.0  1705.510147  2998.602415     0.000000   \n",
       "total_rech_data             159109.0     3.435053     7.229865     0.000000   \n",
       "vol_4g                      159109.0   191.741808   590.745873     0.000000   \n",
       "vol_5g                      159109.0  2267.762985  4595.365953     0.000000   \n",
       "Month                       159109.0     9.408556     3.450255     1.000000   \n",
       "Month of Joining            159109.0     6.175848     2.879792     1.000000   \n",
       "\n",
       "                               25%     50%          75%           max  \n",
       "Age                          28.00   34.00    43.000000     80.000000  \n",
       "Device Protection Plan        0.00    0.00     1.000000      1.000000  \n",
       "Gender                        0.00    1.00     1.000000      3.000000  \n",
       "Internet Service              0.00    1.00     1.000000      1.000000  \n",
       "Internet Type                 1.00    2.00     3.000000      3.000000  \n",
       "Married                       0.00    1.00     2.000000      2.000000  \n",
       "Multiple Lines                0.00    1.00     1.000000      2.000000  \n",
       "Number of Dependents          0.00    0.00     1.000000      9.000000  \n",
       "Number of Referrals           0.00    4.00     8.000000     11.000000  \n",
       "Online Backup                 0.00    0.00     1.000000      1.000000  \n",
       "Online Security               0.00    0.00     0.000000      1.000000  \n",
       "Payment Method                0.00    0.00     1.000000      2.000000  \n",
       "Phone Service                 1.00    1.00     1.000000      1.000000  \n",
       "Premium Tech Support          0.00    0.00     1.000000      1.000000  \n",
       "Streaming Data Consumption    2.00   20.00    49.000000     85.000000  \n",
       "Streaming Movies              0.00    0.00     1.000000      1.000000  \n",
       "Streaming Music               0.00    0.00     1.000000      1.000000  \n",
       "Streaming TV                  0.00    0.00     1.000000      1.000000  \n",
       "Unlimited Data                0.00    1.00     1.000000      2.000000  \n",
       "area_codes                   78.00  101.00   147.000000    174.000000  \n",
       "arpu                        118.31  348.41   582.400000   9393.940000  \n",
       "arpu_4g                       0.00    0.00   112.630000   8839.721689  \n",
       "arpu_5g                       0.00    0.00   100.440000   8724.440600  \n",
       "aug_vbc_5g                    0.00  117.53   311.790000   8213.830000  \n",
       "ic_others                    20.28   40.65    60.950000   1344.130000  \n",
       "isd_ic                       27.45   54.45    96.630000   1873.110208  \n",
       "isd_og                        3.20   17.31    31.300000    764.810000  \n",
       "loc_ic_t2f                   36.39   72.81   513.910000   1872.340000  \n",
       "loc_ic_t2m                   85.68  170.63  1123.240000   3783.530000  \n",
       "loc_ic_t2t                   87.10  173.79  1289.270000   4363.950000  \n",
       "loc_og_t2c                    1.59    8.21    14.740000    336.120000  \n",
       "loc_og_t2f                    1.47    7.92    18.110000    283.510000  \n",
       "loc_og_t2m                   26.42  136.78   706.180000   4212.010000  \n",
       "loc_og_t2t                   33.18  174.06   313.460000   6431.100000  \n",
       "og_others                     3.42   17.99   116.830000    609.770000  \n",
       "roam_ic                      12.18   51.21   196.853003   1719.420000  \n",
       "roam_og                      14.40   75.02   135.550000   3161.740000  \n",
       "spl_ic                        0.04    0.08     0.210000      2.330000  \n",
       "spl_og                        4.96   26.16    46.960000   1018.760000  \n",
       "std_ic_t2f                   12.61   25.31   193.570000    663.920000  \n",
       "std_ic_t2m                   32.51   65.54   460.946724   1619.680000  \n",
       "std_ic_t2o                    0.00    0.00     0.000000      0.000000  \n",
       "std_ic_t2t                   42.88   85.67   217.137387   2527.000000  \n",
       "std_og_t2c                    0.00    0.00     0.000000      0.000000  \n",
       "std_og_t2f                    1.19    6.38    42.200000    217.430000  \n",
       "std_og_t2m                   25.17  134.70   245.690000   5622.020000  \n",
       "std_og_t2t                   32.70  175.88   318.040000   7366.060000  \n",
       "tenure                        1.00    3.00     5.000000     13.000000  \n",
       "total_rech_amt               72.00  375.00  1108.000000  11899.000000  \n",
       "total_rech_data               0.00    0.00     2.000000     32.000000  \n",
       "vol_4g                        0.00   47.35   154.600000   4503.670000  \n",
       "vol_5g                        0.00  289.16   900.670000  19872.850000  \n",
       "Month                         7.00   10.00    12.000000     14.000000  \n",
       "Month of Joining              4.00    6.00     8.000000     12.000000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat_enc.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train_feat_enc,train_id[['Customer ID','Month','Month of Joining','Churn Value','offer']],how = 'inner',on=['Customer ID','Month','Month of Joining'])\n",
    "production = pd.merge(prod_feat_enc,prod_id[['Customer ID','Month','Month of Joining','Churn Value','offer']],how = 'inner',on=['Customer ID','Month','Month of Joining'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159109\n",
      "494644\n"
     ]
    }
   ],
   "source": [
    "## This help us check if we did not duplicate anything in the columns\n",
    "\n",
    "print(len(train))\n",
    "print(len(production))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Building and Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Collaborative filtering**\n",
    "\n",
    "Collaborative filtering is a type of recommendation system that uses user feedback to make personalized recommendations for items. It works by finding similarities between users or items and using those similarities to make predictions about what a user might like or dislike.\n",
    "\n",
    "Collaborative filtering can be broken down into two main types: user-based and item-based. In user-based collaborative filtering, similarities are calculated between users based on their past interactions with items. In item-based collaborative filtering, similarities are calculated between items based on how often they are interacted with by the same users.\n",
    "\n",
    "Distance measures are commonly used in collaborative filtering to calculate similarities between users or items. Some common distance measures used in collaborative filtering include Manhattan distance, Euclidean distance, and cosine similarity.\n",
    "\n",
    "The basic idea behind using distance measures in collaborative filtering is that similar users or items will be close together in the feature space defined by the data. For example, if we are recommending movies to users based on their past movie ratings, we might represent each user as a vector of their ratings, with each rating corresponding to a different movie. We could then calculate the distance between two users' rating vectors using a distance measure like cosine similarity or Euclidean distance. Users who have similar ratings for the same movies will be closer together in this feature space and therefore will have a smaller distance between them.\n",
    "\n",
    "Once we have calculated similarities between users or items, we can use those similarities to make predictions about what a user might like or dislike. For example, if we have calculated the similarity between two users and we know that one of them likes a certain movie, we can predict that the other user might also like that movie based on their similarity.\n",
    "\n",
    "There are many variations of collaborative filtering that use different distance measures and algorithms for finding similarities between users or items. Some examples include k-nearest neighbors (k-NN), which uses the distances between users to find the k users who are most similar to a given user, and matrix factorization, which uses linear algebra techniques to decompose the user-item interaction matrix into lower-dimensional matrices that capture user and item characteristics.\n",
    "\n",
    "In summary, collaborative filtering is a type of recommendation system that uses user feedback to make personalized recommendations for items. It uses distance measures to calculate similarities between users or items, which are then used to make predictions about what a user might like or dislike."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mathematical explanation for distance measure**\n",
    "\n",
    "Manhattan, cosine, and Euclidean distance are different distance metrics used in machine learning and data science.\n",
    "\n",
    "### **Manhattan distance:**\n",
    "Manhattan distance, also known as taxicab distance or L1 distance, is a measure of the distance between two points in a n-dimensional space. It is called Manhattan distance because it is analogous to the distance a taxi would travel on the streets of Manhattan, where you can only move in straight lines along the grid.\n",
    "The formula for Manhattan distance between two points P and Q in n-dimensional space is:\n",
    "\n",
    "\\begin{equation}\n",
    "d(P,Q) = |x_1-y_1| + |x_2-y_2| + ... + |x_n-y_n|\n",
    "\\end{equation}\n",
    "\n",
    "where $x_1, x_2, ..., x_n$ are the coordinates of point $P$ and $y_1, y_2, ..., y_n$ are the coordinates of point $Q$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cosine similarity:**\n",
    "Cosine similarity is a measure of the similarity between two non-zero vectors of an inner product space. It is the cosine of the angle between the two vectors and ranges from -1 to 1. A value of 1 indicates that the two vectors are identical, while a value of -1 indicates that they are completely dissimilar.\n",
    "The formula for cosine similarity between two vectors A and B is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{cosine   similarity}(A, B) = \\frac{A * B }{ ||A|| * ||B||}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "where $A * B$ is the dot product of vectors A and B, and $||A||$ and $||B||$ are the magnitudes of vectors A and B, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommended_offers (df:pd.DataFrame, df_id:pd.DataFrame,customer_id:str,month:int,distance_func:str,n,minimal_threshold:float,max_offers_to_return:int):\n",
    "    \"\"\"\n",
    "    This function takes as parameters:\n",
    "    1. the dataframe where we'll be getting our data\n",
    "    2. the customer identifiers Customer Id and the Month we want to make an offer for\n",
    "    3. the distance function we want to use to calculate similaries between customers (see explanation below on how to chose it)\n",
    "    4. The number of other customers we want to base our recommendations on\n",
    "    5. The minimal threshold of prevalence of a given offer, in the similar group of customers, for it to be considered for recommendation (see explanation below on how to chose it)\n",
    "    \n",
    "    It returns:\n",
    "    An array with the list of offers that we could recommend to this customer\n",
    "    \"\"\"\n",
    "\n",
    "    # extract the feature vectors of all customers\n",
    "    features = list(df.columns.difference(['Customer ID','Month','Month of Joining','offer']))\n",
    "    X = df[features].values\n",
    "\n",
    "    # extract the feature vector of the given customer\n",
    "    index = df[(df['Customer ID'] == customer_id) & (df['Month']==month)].index[0]\n",
    "    x = X[index]\n",
    "\n",
    "    # compute the distances between the feature vectors\n",
    "    if distance_func == 'euclidean':\n",
    "      distances = euclidean_distances(X, x.reshape(1, -1)).flatten()\n",
    "    elif distance_func == 'manhattan':\n",
    "      distances = manhattan_distances(X, x.reshape(1, -1)).flatten()\n",
    "    elif distance_func == 'cosine':\n",
    "      distances = 1 - cosine_similarity(X, x.reshape(1, -1)).flatten()\n",
    "    else:\n",
    "      raise ValueError('Invalid distance function specified.')\n",
    "\n",
    "    # find the indices of the n customers with lowest distance\n",
    "    most_similar_indices = distances.argsort()[:n]\n",
    "            \n",
    "    # extract the customer data for the most similar customers\n",
    "    similar_customers = df.iloc[most_similar_indices]\n",
    "\n",
    "    # merge with the id dataframe to select only the customers who did not churn\n",
    "    similar_customers = pd.merge(similar_customers,df_id[['Customer ID','Month of Joining','Month','Churn Value']],on=['Customer ID','Month of Joining','Month','Churn Value'])\n",
    "\n",
    "    # select the customers that did not churn\n",
    "    similar_customers = similar_customers[similar_customers['Churn Value']==0]\n",
    "\n",
    "    #count the top offers of the non-churned customers\n",
    "    top_offers = similar_customers[['Customer ID','offer']].groupby(['offer']).agg({'Customer ID':'count'}).reset_index().sort_values(by = 'Customer ID', ascending = False)\n",
    "    top_offers['perc_total'] = top_offers['Customer ID']/top_offers['Customer ID'].sum()\n",
    "    top_offers_min = top_offers[top_offers['perc_total']>minimal_threshold].head(max_offers_to_return)\n",
    "        \n",
    "    return top_offers_min['offer'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Function Overview**\n",
    "\n",
    "This function finds n similar customers with respect to the distance metric provided by user from training data corresponding to specific customer. \n",
    "\n",
    "It further finds the most occurring offers given to set of n similar customers and recommend the top 3 offers.\n",
    "\n",
    "\n",
    "##### **Input Parameters**\n",
    "1. df: The main DataFrame that contains all the data for all customers and their offers\n",
    "\n",
    "2. df_id: A DataFrame that contains only the customer ID, month of joining, and churn value and offer\n",
    "\n",
    "3. customer_id: The ID of the customer we want to recommend offers for\n",
    "\n",
    "4. month: The month we want to make the offer for\n",
    "\n",
    "5. distance_func: The distance function to use for finding similar customers\n",
    "\n",
    "6. n: The number of other customers we want to base our recommendations on\n",
    "\n",
    "7. minimal_threshold: The minimal threshold of prevalence of a given offer in the similar group of customers, for it to be considered for recommendation\n",
    "\n",
    "8. max_offers_to_return: The maximum number of offers to return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step by Step Explanation**\n",
    "\n",
    "* Extracts the feature vectors of all customers by removing the 'Customer ID', 'Month', 'Month of Joining', and 'offer' columns from the main DataFrame\n",
    "\n",
    "```\n",
    "features = list(df.columns.difference(['Customer ID','Month','Month of Joining','offer']))\n",
    "X = df[features].values\n",
    "```\n",
    "\n",
    "* Extracts the feature vector of the given customer\n",
    "\n",
    "```\n",
    "index = df[(df['Customer ID'] == customer_id) & (df['Month']==month)].index[0]\n",
    "x = X[index]\n",
    "```\n",
    "\n",
    "* Computes the distances between the feature vectors of the given customer and all other customers using the specified distance function\n",
    "\n",
    "```\n",
    "if distance_func == 'euclidean':\n",
    "    distances = euclidean_distances(X, x.reshape(1, -1)).flatten()\n",
    "elif distance_func == 'manhattan':\n",
    "    distances = manhattan_distances(X, x.reshape(1, -1)).flatten()\n",
    "elif distance_func == 'cosine':\n",
    "     distances = 1 - cosine_similarity(X, x.reshape(1, -1)).flatten()\n",
    "else:\n",
    "    raise ValueError('Invalid distance function specified.')\n",
    "```\n",
    "\n",
    "* Finds the indices of the n customers with the lowest distance to the given customer\n",
    "\n",
    "```\n",
    "most_similar_indices = distances.argsort()[:n]\n",
    "```\n",
    "\n",
    "* Extracts the customer data for the most similar customers\n",
    "\n",
    "```\n",
    "similar_customers = df.iloc[most_similar_indices]\n",
    "```\n",
    "\n",
    "* Merges the similar customers DataFrame with the ID DataFrame to select only the customers who did not churn\n",
    "\n",
    "```\n",
    "similar_customers = pd.merge(similar_customers,df_id[['Customer ID','Month of Joining','Month','Churn Value']],on=['Customer ID','Month of Joining','Month','Churn Value'])\n",
    "```\n",
    "\n",
    "* Selects the customers that did not churn\n",
    "\n",
    "```\n",
    "similar_customers = similar_customers[similar_customers['Churn Value']==0]\n",
    "```\n",
    "\n",
    "* Counts the top offers of the non-churned customers, calculates the percentage of each offer among the top offers, and selects the top max_offers_to_return offers whose percentage is above the minimal_threshold\n",
    "\n",
    "```\n",
    "top_offers = similar_customers[['Customer ID','offer']].groupby(['offer']).agg({'Customer ID':'count'}).reset_index().sort_values(by = 'Customer ID', ascending = False)\n",
    "top_offers['perc_total'] = top_offers['Customer ID']/top_offers['Customer ID'].sum()\n",
    "top_offers_min = top_offers[top_offers['perc_total']>minimal_threshold].head\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The minimal threshold parameter**\n",
    "\n",
    "Whenever we are building any framework, and especially unsupervised ones, it is important that we establish parameters that can help us have confidence in what we are doing.\n",
    "\n",
    "In this particular case, we are assigning a minimal threshold of 10% for an offer to be potentially chosen to customers.\n",
    "\n",
    "This comes from the fact that we have 10 offers (A-> J). If we were to randomly assign an offer to a customer, we would likely give each offer an equal probability of being assigned, so 100%/10%. So given that, if we are going to recommend something, it needs to be better than the random assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify similar customers, we are going to treat each feature that we selected now in the train dataframe as a customer feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Which distance to choose?**\n",
    "\n",
    "In Summary\n",
    "*  Manhattan distance: This metric measures the distance between two points by summing the absolute differences between their coordinates. It is also called the \"taxicab\" or \"city block\" distance because it measures the distance a taxicab would have to travel to get from one point to another on a city grid. \n",
    "\n",
    "*  Cosine similarity: This metric measures the cosine of the angle between two vectors in a high-dimensional space. It is commonly used in text analysis and information retrieval to measure the similarity between documents. Cosine similarity is often preferred over Euclidean distance when the magnitude of the vectors is not important, and only the direction matters.\n",
    "\n",
    "*  Euclidean distance: This metric measures the distance between two points in a straight line. It is the most common distance metric used in machine learning and data science. Euclidean distance is useful when the data is dense, and the features have similar scales.\n",
    "\n",
    "In general, if you have high-dimensional data or sparse data, Manhattan or cosine distance may be more appropriate. If you have dense data with similar scales, Euclidean distance is a good choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Applying this framework to a specific customer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Device Protection Plan</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Internet Service</th>\n",
       "      <th>Internet Type</th>\n",
       "      <th>Married</th>\n",
       "      <th>Multiple Lines</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Number of Referrals</th>\n",
       "      <th>Online Backup</th>\n",
       "      <th>...</th>\n",
       "      <th>tenure</th>\n",
       "      <th>total_rech_amt</th>\n",
       "      <th>total_rech_data</th>\n",
       "      <th>vol_4g</th>\n",
       "      <th>vol_5g</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Month of Joining</th>\n",
       "      <th>Churn Value</th>\n",
       "      <th>offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>452</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.04</td>\n",
       "      <td>127.5</td>\n",
       "      <td>sirifvlkipkel21</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Device Protection Plan  Gender  Internet Service  Internet Type  \\\n",
       "24  40.0                       0       0                 1              0   \n",
       "\n",
       "    Married  Multiple Lines  Number of Dependents  Number of Referrals  \\\n",
       "24        2               0                   0.0                 10.0   \n",
       "\n",
       "    Online Backup  ...  tenure  total_rech_amt  total_rech_data  vol_4g  \\\n",
       "24              0  ...       1             452              3.0   12.04   \n",
       "\n",
       "    vol_5g      Customer ID  Month  Month of Joining  Churn Value  offer  \n",
       "24   127.5  sirifvlkipkel21     12                11            0      G  \n",
       "\n",
       "[1 rows x 57 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Customer ID']=='sirifvlkipkel21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first offer to recommend is C\n",
      "The second offer to recommend is G\n",
      "The third offer to recommend is F\n"
     ]
    }
   ],
   "source": [
    "customer_id = 'sirifvlkipkel21' # This Customer Id needs to be there from the training dataset\n",
    "month = 12\n",
    "distance_func = 'euclidean'\n",
    "n = 1000\n",
    "minimal_threshold= 0.10\n",
    "max_offers_to_return = 3\n",
    "id_cols=['Customer ID','Month','Month of Joining','Churn Value','offer']\n",
    "\n",
    "offers = get_recommended_offers(train, train[id_cols], customer_id,month,distance_func,n,minimal_threshold,max_offers_to_return)\n",
    "\n",
    "print('The first offer to recommend is ' + str(offers[0]))\n",
    "print('The second offer to recommend is ' + str(offers[1]))\n",
    "print('The third offer to recommend is ' + str(offers[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of adding this result to a list, we could also add it to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>offer 1</th>\n",
       "      <th>offer 2</th>\n",
       "      <th>offer 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sirifvlkipkel21</td>\n",
       "      <td>12</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Customer ID  Month offer 1 offer 2 offer 3\n",
       "0  sirifvlkipkel21     12       C       G       F"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame()\n",
    "\n",
    "data = {'Customer ID': [customer_id],\n",
    "        'Month': [month],\n",
    "        'offer 1': [str(offers[0])],\n",
    "        'offer 2': [str(offers[1])],\n",
    "        'offer 3': [str(offers[2])]}\n",
    "\n",
    "frame= pd.DataFrame(data)\n",
    "frame.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bootstrapping the framework**\n",
    "\n",
    "\n",
    "Especially in unsupervised learning problems, it is always a good idea to run several approaches ('bootstrap') and chose the most common answer amongst the different models. This mechanism is similar to what algorithms like random forest do, for example: they fit several trees and each tree votes the final classification of a sample.\n",
    "\n",
    "We are going to play with the 3 distances we have in our function + the number of customers we pull the data from in order to get a voted answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_customers_multiple(df:pd.DataFrame, df_id:pd.DataFrame,customer_id:str,month:int,distance_funcs:list,n_values,minimal_threshold:float,max_offers_to_return:int):\n",
    "    \"\"\"\n",
    "    Given a dataframe, a customer_id, n values, and distance functions,\n",
    "    run multiple iterations of the find_similar_customers function with different parameter combinations,\n",
    "    and return the top 3 most common answers among those.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for n in n_values:\n",
    "      for distance_func in distance_funcs:\n",
    "          result = get_recommended_offers (df,df_id ,customer_id,month,distance_func,n,minimal_threshold,max_offers_to_return)\n",
    "          results.append(result)\n",
    "          # concatenate the arrays together\n",
    "          concatenated_array = np.concatenate(results)\n",
    "          # convert the concatenated array to a Python list\n",
    "          result_list = list(concatenated_array)\n",
    "          result_list\n",
    "    if len(results) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        result_counts = pd.Series(result_list).value_counts()\n",
    "        most_common_result = [result_counts.index[0],result_counts.index[1],result_counts.index[2]]\n",
    "        return most_common_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Function Overview**\n",
    "\n",
    "This function takes a dataframe, a customer ID, a month, a list of distance functions, a list of n values, a minimal threshold, and a max number of offers to return as input parameters. It uses these parameters to run multiple iterations of the get_recommended_offers function and returns the top 3 most common recommendations among them.\n",
    "\n",
    "First, the function initializes an empty results list to store the results of each iteration. Then, for each n value and distance function, it calls the get_recommended_offers function with the given parameters and appends the result to the results list. After all iterations are completed, the function concatenates the arrays together and converts them to a Python list.\n",
    "\n",
    "If the results list is empty, meaning no recommendations were generated, the function returns None. Otherwise, it uses the value_counts() function to count the frequency of each recommended offer in the result_list, and returns a list of the top 3 most common recommendations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Applying this framework to a given customer** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G', 'A', 'I']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_values = [100, 250, 500, 1000]\n",
    "distance_funcs = ['euclidean', 'manhattan', 'cosine']\n",
    "customer_id = 'sirifvlkipkel21'\n",
    "month = 12\n",
    "minimal_threshold= 0.10\n",
    "max_offers_to_return = 3\n",
    "id_cols=['Customer ID','Month','Month of Joining','Churn Value','offer']\n",
    "find_similar_customers_multiple(train, train[id_cols],customer_id,month,distance_funcs,n_values,minimal_threshold=0.10,max_offers_to_return=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing how this function work in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter values\n",
    "n_values = [100, 250, 500, 1000]\n",
    "distance_funcs = ['euclidean', 'manhattan', 'cosine']\n",
    "customer_id = 'sirifvlkipkel21'\n",
    "month = 12\n",
    "minimal_threshold= 0.10\n",
    "max_offers_to_return = 3\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each value in n_values \n",
    "# The number of other customers we want to base our recommendations on\n",
    "for n in n_values:\n",
    "  # chose distance metric from a list\n",
    "  for distance_func in distance_funcs:\n",
    "    \n",
    "      # get the offer recommendation by using get_recommended_offers function\n",
    "      result = get_recommended_offers (train, train[id_cols],customer_id,month,distance_func,n,minimal_threshold,max_offers_to_return)\n",
    "      \n",
    "      results.append(result)\n",
    "      # concatenate the arrays together\n",
    "      concatenated_array = np.concatenate(results)\n",
    "      # convert the concatenated array to a Python list\n",
    "      result_list = list(concatenated_array)\n",
    "if len(results) == 0:\n",
    "    None\n",
    "else:\n",
    "    result_counts = pd.Series(result_list).value_counts()\n",
    "    most_common_result = [result_counts.index[0],result_counts.index[1],result_counts.index[2]]\n",
    "    most_common_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G    10\n",
       "A     7\n",
       "I     5\n",
       "C     5\n",
       "J     4\n",
       "D     3\n",
       "F     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_counts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that the different iterations returned 7 potential offers. 3 of those were, however, much more common than 6 of the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G', 'A', 'I']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most_common_result list will aggregate the top 3 offers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Applying this to the whole dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a function called production_model that takes three arguments: df, distance_func, and n. df is a Pandas DataFrame that contains data about customer transactions. The distance_func is a function that takes two arguments and returns a distance measure between them. The n parameter specifies the number of recommended offers to return for each customer and month.\n",
    "\n",
    "The function initializes an empty DataFrame called frame and then iterates over each unique customer in the input DataFrame. For each customer, the function iterates over each unique month for that customer and calls another function called get_recommended_offers. This function returns a list of recommended offers for that customer and month based on their transaction history, using the distance_func and n parameters.\n",
    "\n",
    "The function then creates a new DataFrame called frame1 containing the Customer ID, Month, and the top three recommended offers for that customer and month, and appends it to the frame DataFrame. Finally, the function returns the frame DataFrame containing the recommendations for all customers and months in the input DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Device Protection Plan</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Internet Service</th>\n",
       "      <th>Internet Type</th>\n",
       "      <th>Married</th>\n",
       "      <th>Multiple Lines</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Number of Referrals</th>\n",
       "      <th>Online Backup</th>\n",
       "      <th>...</th>\n",
       "      <th>tenure</th>\n",
       "      <th>total_rech_amt</th>\n",
       "      <th>total_rech_data</th>\n",
       "      <th>vol_4g</th>\n",
       "      <th>vol_5g</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Month of Joining</th>\n",
       "      <th>Churn Value</th>\n",
       "      <th>offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.3</td>\n",
       "      <td>219.25</td>\n",
       "      <td>hthjctifkiudi0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.472065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age  Device Protection Plan  Gender  Internet Service  Internet Type  \\\n",
       "0  36.000000                       1       0                 1              1   \n",
       "1  36.472065                       0       1                 0              3   \n",
       "\n",
       "   Married  Multiple Lines  Number of Dependents  Number of Referrals  \\\n",
       "0        0               1                   0.0                  9.0   \n",
       "1        0               1                   0.0                  0.0   \n",
       "\n",
       "   Online Backup  ...  tenure  total_rech_amt  total_rech_data  vol_4g  \\\n",
       "0              0  ...       0              18              0.0    38.3   \n",
       "1              1  ...       0            1183              0.0     0.0   \n",
       "\n",
       "   vol_5g     Customer ID  Month  Month of Joining  Churn Value  offer  \n",
       "0  219.25  hthjctifkiudi0      1                 1            1      A  \n",
       "1    0.00  uqdtniwvxqzeu1      6                 6            0      F  \n",
       "\n",
       "[2 rows x 57 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **For the function without bootstrapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer ID', 'Month', 'Month of Joining', 'offer', 'Churn Category',\n",
       "       'Churn Reason', 'Customer Status', 'Churn Value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def production_model(df, train, production, distance_func, n):\n",
    "    frame = pd.DataFrame()\n",
    "    # Pour chaque client et chaque mois\n",
    "    for customer in list(df['Customer ID'].unique()):\n",
    "        for month in list(df[df['Customer ID'] == customer]['Month'].unique()):\n",
    "            # Cette partie du code ajoute la ligne que nous voulons obtenir des offres à l'ensemble d'entraînement, afin que nous puissions utiliser la formule de distance\n",
    "            data = pd.DataFrame()\n",
    "            data = pd.concat([train, production[(production['Customer ID'] == customer) & (production['Month'] == month)]])\n",
    "            data = data.reset_index()\n",
    "            data_id = data[['Customer ID', 'Month', 'Month of Joining', 'Churn Value']]\n",
    "            results = get_recommended_offers(data, data_id, customer, month, distance_func, n, minimal_threshold=0.10, max_offers_to_return=3)\n",
    "            data = {'Customer ID': [customer],\n",
    "                    'Month': [month],\n",
    "                    'offers': [results]}\n",
    "            frame1 = pd.DataFrame(data)\n",
    "            frame = frame._append([frame1])\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Function Overview**\n",
    "\n",
    "The production_model function takes in a dataframe df, a distance function distance_func, and a value n, and returns a new dataframe frame with recommended offer in each month.\n",
    "\n",
    "For each unique Customer ID and Month combination in the input dataframe, the function adds the line for that combination to a new dataframe data that includes all previous training data plus the current combination. The get_recommended_offers function is then called on this new data dataframe, using the given distance_func and n values, to obtain a list of recommended offers for that combination.\n",
    "\n",
    "A dictionary is then created to store the Customer ID, Month, and offers data, and a new dataframe frame1 is created from this dictionary. This new dataframe is then appended to the existing frame dataframe.\n",
    "\n",
    "Finally, the frame dataframe is returned, which contains the recommended offers for each unique Customer ID and Month combination in the input dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_production_100_samples = production_model(production.head(100),train=train,production=production,distance_func = 'euclidean',n = 250)\n",
    "frame_production_100_samples.to_csv('./data/output/offer_recommendation_without_bootstap.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>offers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>7</td>\n",
       "      <td>[J, F, E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>9</td>\n",
       "      <td>[F, E, A]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>10</td>\n",
       "      <td>[E, A, F]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>11</td>\n",
       "      <td>[F, A, G]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>12</td>\n",
       "      <td>[I, B, C]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer ID  Month     offers\n",
       "0  uqdtniwvxqzeu1      7  [J, F, E]\n",
       "0  uqdtniwvxqzeu1      9  [F, E, A]\n",
       "0  uqdtniwvxqzeu1     10  [E, A, F]\n",
       "0  uqdtniwvxqzeu1     11  [F, A, G]\n",
       "0  uqdtniwvxqzeu1     12  [I, B, C]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_production_100_samples.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **For the function with bootstrapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def production_model_bootstrap(df, train, production, distance_funcs, n_values):\n",
    "    frame = pd.DataFrame()\n",
    "    for customer in list(df['Customer ID'].unique()):\n",
    "        for month in list(df[df['Customer ID'] == customer]['Month'].unique()):\n",
    "            # Cette partie du code ajoute la ligne que nous voulons obtenir des offres à l'ensemble d'entraînement, afin que nous puissions utiliser la formule de distance\n",
    "            data = pd.DataFrame()\n",
    "            data = pd.concat([train, production[(production['Customer ID'] == customer) & (production['Month'] == month)]])\n",
    "            data = data.reset_index()\n",
    "            data_id = data[['Customer ID', 'Month', 'Month of Joining', 'Churn Value']]\n",
    "            results = find_similar_customers_multiple(data, data_id, customer, month, distance_funcs=distance_funcs, n_values=n_values, minimal_threshold=0.10, max_offers_to_return=3)\n",
    "            data = {'Customer ID': [customer],\n",
    "                    'Month': [month],\n",
    "                    'offers': [results]}\n",
    "            frame1 = pd.DataFrame(data)\n",
    "            frame = frame._append(frame1)\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Function Overview**\n",
    "\n",
    "The production_model function takes in a dataframe df, a distance function distance_func, and a value n, and returns a new dataframe frame with recommended offer in each month.\n",
    "\n",
    "For each unique Customer ID and Month combination in the input dataframe, the function adds the line for that combination to a new dataframe data that includes all previous training data plus the current combination. The find_similar_customers_multiple(boostraping function) function is then called on this new data dataframe, using the given distance_func and n values, to obtain a list of recommended offers for that combination.\n",
    "\n",
    "A dictionary is then created to store the Customer ID, Month, and offers data, and a new dataframe frame1 is created from this dictionary. This new dataframe is then appended to the existing frame dataframe.\n",
    "\n",
    "Finally, the frame dataframe is returned, which contains the recommended offers for each unique Customer ID and Month combination in the input dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_production_100_samples_bootstrap = production_model_bootstrap (production.head(100),train=train,production=production,distance_funcs=['euclidean', 'manhattan', 'cosine'],n_values=[250,500,1000])\n",
    "frame_production_100_samples_bootstrap.to_csv('./data/output/offer_recommendation_bootstrap.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>offers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>7</td>\n",
       "      <td>[E, J, F]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>9</td>\n",
       "      <td>[F, J, E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>10</td>\n",
       "      <td>[J, E, F]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>11</td>\n",
       "      <td>[F, J, E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>12</td>\n",
       "      <td>[C, F, I]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer ID  Month     offers\n",
       "0  uqdtniwvxqzeu1      7  [E, J, F]\n",
       "0  uqdtniwvxqzeu1      9  [F, J, E]\n",
       "0  uqdtniwvxqzeu1     10  [J, E, F]\n",
       "0  uqdtniwvxqzeu1     11  [F, J, E]\n",
       "0  uqdtniwvxqzeu1     12  [C, F, I]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_production_100_samples_bootstrap.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Questions**\n",
    "\n",
    "\n",
    "How would you validate this approach?\n",
    "- You ideally could design a test where, for some control group, you offer a random offer (or use whatever method is used today). For some treatment, you use your model to assign the offer. You could then measure retention of these two groups;\n",
    "\n",
    "- Another option would be to train this model on part of the training set, and use another part of the training set to test it. You could check if you have recommended a 'winning offer', where 'winning' = an offer where that was taken by the customer and avoided churn in the next month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "In this project we used a simple yet effective unsupervised model to provide offers to customers.\n",
    "\n",
    "A collaborative offer recommendation system can be a valuable tool for telecom companies to increase customer satisfaction and revenue. By using data on customer behavior and preferences, the system can provide personalized offers that are more likely to be accepted by customers.\n",
    "\n",
    "To implement such a system, several steps need to be taken, including collecting and cleaning data, creating customer profiles, selecting appropriate distance functions, and validating the system's performance. It is also essential to consider ethical considerations related to data privacy and security.\n",
    "\n",
    "Overall, a collaborative offer recommendation system can be a powerful tool for telecom companies to enhance their marketing strategies and provide better services to their customers. However, it is important to continuously evaluate and update the system to ensure its effectiveness and address any potential issues.\n",
    "\n",
    "\n",
    "In conclusion, a successful data science project requires a clear understanding of the business problem and the data available, as well as the ability to select and apply appropriate data preprocessing techniques, feature engineering methods, and machine learning algorithms. It is also important to assess and optimize the performance of the model and communicate the results effectively to stakeholders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Questions to know how to answer**\n",
    "\n",
    "### **Collaborative Filtering:**\n",
    "\n",
    "* What is collaborative filtering and how does it work?\n",
    "* Can you explain the difference between user-based and item-based collaborative filtering?\n",
    "* Can you give an example of how collaborative filtering is used in real-world applications?\n",
    "\n",
    "### **Distance Measures:**\n",
    "\n",
    "* What are distance measures and why are they important in data science?\n",
    "* Can you explain the difference between Euclidean distance and Manhattan distance?\n",
    "\n",
    "\n",
    "### **Code Implementation:**\n",
    "\n",
    "* Can you walk me through the code for the get_recommended_offers function?\n",
    "* How does the find_similar_customers_multiple function work?\n",
    "* Can you explain the purpose of the production_model function and how it uses the get_recommended_offers function?\n",
    "* How would you modify these functions to handle larger datasets or improve their performance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
